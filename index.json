[{"authors":["alex"],"categories":null,"content":"Alex Gates is an assistant professor in the School of Data Science at the University of Virginia, researching how connectivity shapes the scientific, social, business world around us.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"d7149a99f41440e55ea517c3fb5d3c99","permalink":"https://uvaDS8104.github.io/authors/alex/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/alex/","section":"authors","summary":"Alex Gates is an assistant professor in the School of Data Science at the University of Virginia, researching how connectivity shapes the scientific, social, business world around us.","tags":null,"title":"Alex Gates","type":"authors"},{"authors":null,"categories":null,"content":"  I have included a bunch of extra resources and guides related to graphic design, visualization, R, data, and other relevant topics. Enjoy!\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"8939c748f3090c6f91bdac5d32db55ec","permalink":"https://uvaDS8104.github.io/resource/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/","section":"resource","summary":"I have included a bunch of extra resources and guides related to graphic design, visualization, R, data, and other relevant topics. Enjoy!","tags":null,"title":"Helpful resources","type":"docs"},{"authors":null,"categories":null,"content":"   Reflections Exercises Mini projects Final project   You will get the most of out this class if you:\nEngage with the readings and lecture materials Regularly use R  Each type of assignment in this class helps with one of these strategies.\nReflections To encourage engagement with the course content, you’ll need to write a ≈150 word reflection about the readings and lectures for the day. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nYou can do a lot of different things with this memo: discuss something you learned from the course content, write about the best or worst data visualization you saw recently, connect the course content to your own work, etc. These reflections let you explore and answer some of the key questions of this course, including:\n What is truth? How is truth related to visualization? Why do we visualize data? What makes a great visualization? What makes a bad visualization? How do you choose which kind of visualization to use? What is the role of stories in presenting analysis?  The course content for each day will also include a set of questions specific to that topic. You do not have to answer all (or any) of these questions. That would be impossible. They exist to guide your thinking, that’s all.\nI will grade these memos using a check system:\n ✔+: (11.5 points (115%) in gradebook) Reflection shows phenomenal thought and engagement with the course content. I will not assign these often. ✔: (10 points (100%) in gradebook) Reflection is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance. ✔−: (5 points (50%) in gradebook) Reflection is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.  Notice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, that’s all. Do good work and you’ll get a ✓.\nYou will turn these reflections in via iCollege. You will write them using R Markdown and they will be the first section of your daily exercises (see below).\n Exercises Each class session has interactive lessons and fully annotated examples of code that teach and demonstrate how to do specific tasks in R. However, without practicing these principles and making graphics on your own, you won’t remember what you learn!\nTo practice working with ggplot2 and making data-based graphics, you will complete a brief set of exercises for each class session. These exercises will have 1–3 short tasks that are directly related to the topic for the day. You need to show that you made a good faith effort to work each question. The problem sets will also be graded using a check system:\n ✔+: (11.5 points (115%) in gradebook) Exercises are 100% completed. Every task was attempted and answered, and most answers are correct. Knitted document is clean and easy to follow. Work is exceptional. I will not assign these often. ✔: (10 points (100%) in gradebook) Exercises are 70–99% complete and most answers are correct. This is the expected level of performance. ✔−: (5 points (50%) in gradebook) Exercises are less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often.  Note that this is also essentially a pass/fail system. I’m not grading your coding ability, I’m not checking each line of code to make sure it produces some exact final figure, and I’m not looking for perfect. Also note that a ✓ does not require 100% completion—you will sometimes get stuck with weird errors that you can’t solve, or the demands of pandemic living might occasionally become overwhelming. I’m looking for good faith effort, that’s all. Try hard, do good work, and you’ll get a ✓.\nYou may (and should!) work together on the exercises, but you must turn in your own answers.\nYou will turn these exercises in using iCollege. You will include your reflection in the first part of the document—the rest will be your exercise tasks.\n Mini projects To give you practice with the data and design principles you’ll learn in this class, you will complete two mini projects. I will provide you with real-world data and pose one or more questions—you will make a pretty picture to answer those questions.\nThe mini projects will be graded using a check system:\n ✔+: (85 points (≈115%) in gradebook) Project is phenomenally well-designed and uses advanced R techniques. The project uncovers an important story that is not readily apparent from just looking at the raw data. I will not assign these often. ✔: (75 points (100%) in gradebook) Project is fine, follows most design principles, answers a question from the data, and uses R correctly. This is the expected level of performance. ✔−: (37.5 points (50%) in gradebook) Project is missing large components, is poorly designed, does not answer a relevant question, and/or uses R incorrectly. This indicates that you need to improve next time. I will hopefully not assign these often.  Because these mini projects give you practice for the final project, I will provide you with substantial feedback on your design and code.\n Final project At the end of the course, you will demonstrate your data visualization skills by completing a final project.\nComplete details for the final project (including past examples of excellent projects) are here.\nThere is no final exam. This project is your final exam.\nThe project will not be graded using a check system. Instead I will use a rubric to grade four elements of your project:\nTechnical skills Visual design Truth and beauty Story  If you’ve engaged with the course content and completed the exercises and mini projects throughout the course, you should do just fine with the final project.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"https://uvaDS8104.github.io/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Reflections Exercises Mini projects Final project   You will get the most of out this class if you:\nEngage with the readings and lecture materials Regularly use R  Each type of assignment in this class helps with one of these strategies.\nReflections To encourage engagement with the course content, you’ll need to write a ≈150 word reflection about the readings and lectures for the day. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).","tags":null,"title":"Assignment overview","type":"docs"},{"authors":null,"categories":null,"content":"  This section contains fully annotated R code that you can use as a reference for creating your own visualizations. In the lessons section, you sequentially build up your understanding of R and ggplot2; here you can see how all the pieces work together.\nVisit this section after you have finished the readings, lecture videos, and lesson. The examples here will be indispensable for you as you work on your assignments and mini projects.\nEach section also contains videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"00e8826988eea7dfc8b8047b4c0184ce","permalink":"https://uvaDS8104.github.io/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/","section":"example","summary":"This section contains fully annotated R code that you can use as a reference for creating your own visualizations. In the lessons section, you sequentially build up your understanding of R and ggplot2; here you can see how all the pieces work together.\nVisit this section after you have finished the readings, lecture videos, and lesson. The examples here will be indispensable for you as you work on your assignments and mini projects.","tags":null,"title":"Code examples","type":"docs"},{"authors":null,"categories":null,"content":"  Each class session has an interactive lesson that you will work through after doing the readings and watching the lecture. These lessons are a central part of the class—they will teach you how to use ggplot2 and other packages in the tidyverse to create beautiful and truthful visualizations with R.\nInteractive code sections look like this. Make changes in the text box and click on the green “Run Code” button to see the results. Sometimes there will be a button with a hint or solution.\nYour turn: Modify the code here to show the relationship between health and wealth for 2002 instead of 2007.\n  If you’re curious how this works, each interactive code section is a miniature Shiny app hosted at shinyapps.io. Each app uses learnr to provide interactivity, and these learnr apps are embedded in this website with some HTML and Javascript wizardry.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"45e63e789e3cb381d68e4ca47e0a453c","permalink":"https://uvaDS8104.github.io/lesson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/lesson/","section":"lesson","summary":"Each class session has an interactive lesson that you will work through after doing the readings and watching the lecture. These lessons are a central part of the class—they will teach you how to use ggplot2 and other packages in the tidyverse to create beautiful and truthful visualizations with R.\nInteractive code sections look like this. Make changes in the text box and click on the green “Run Code” button to see the results.","tags":null,"title":"Interactive lessons","type":"docs"},{"authors":null,"categories":null,"content":"  Each class session has a set of required readings that you should complete before watching the lecture or working through the lesson.\nI’ve included a set of questions that might guide your reflection response. You should not try to respond to all of these (or any of them if you don’t want to)—they’ll just help you know what to look for and think about as you read.\nEvery class session also has a YouTube playlist of short recorded videos for each of the lecture sections. The lecture slides are special HTML files made with the R package xaringan (R can do so much!). On each class session page you’ll buttons for opening the presentation in a new tab or for downloading a PDF of the slides in case you want to print them or store them on your computer:\n View all slides in new window  Download PDF of all slides The slides are also embedded on each page. You can click in the slides and navigate through them with ← and →. If you type ? (or shift + /) while viewing the slides you can see a list of slide-specific commands (like f for fullscreen or p for presenter mode if you want to see my notes).\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1673993163,"objectID":"1413f960ec974b9863bc45d887efa8bd","permalink":"https://uvaDS8104.github.io/content/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/content/","section":"content","summary":"Each class session has a set of required readings that you should complete before watching the lecture or working through the lesson.\nI’ve included a set of questions that might guide your reflection response. You should not try to respond to all of these (or any of them if you don’t want to)—they’ll just help you know what to look for and think about as you read.\nEvery class session also has a YouTube playlist of short recorded videos for each of the lecture sections.","tags":null,"title":"Readings, lectures, and videos","type":"docs"},{"authors":null,"categories":null,"content":"   Instructions Starter code   New York City is full of urban wildlife, and rats are one of the city’s most infamous animal mascots. Rats in NYC are plentiful, but they also deliver food, so they’re useful too.\n  NYC keeps incredibly detailed data regarding animal sightings, including rats, and it makes this data publicly available.\nFor this first mini project, you will use R and ggplot2 to tell an interesting story hidden in the data. You can recreate one of these ugly, less-than-helpful graphs, or create a new story by looking at other variables in the data:\nInstructions Here’s what you need to do:\nCreate a new RStudio project and place it on your computer somewhere. Open that new folder in Windows File Explorer or macOS Finder (however you navigate around the files on your computer), and create two subfolders there named data and output.\n Download New York City’s database of rat sightings since 2010:\n  Rat_Sightings.csv\n Place this in the data subfolder you created in step 1. You might need to right click on this link and choose “Save link as…”, since your browser may try to display it as text. The data was originally uploaded by the City of New York to Kaggle, and is provided with a public domain license.\n  Create a new R Markdown file and save it in your project. In RStudio go to File \u0026gt; New File \u0026gt; R Markdown…, choose the default options, and delete all the placeholder text in the new file except for the metadata at the top, which is between --- and ---.\n Verify that your project folder is structured like this:\nyour-project-name/ your-analysis.Rmd your-project-name.Rproj data/ Rat_Sightings.csv output/ NOTHING Summarize the data somehow. The raw data has more than 100,000 rows, which means you’ll need to aggregate the data (filter(), group_by(), and summarize() will be your friends). Consider looking at the number of sightings per borough, per year, per dwelling type, etc., or a combination of these, like the change in the number sightings across the 5 boroughs between 2010 and 2016.\n Create an appropriate visualization based on the data you summarized.\n Write a memo (no word limit) explaining your process. I’m specifically looking for a discussion of the following:\n What was wrong with the original graphic (if you’re fixing one of the original figures)? What story are you telling with your new graphic? How did you apply the principles of CRAP? How did you apply Kieran Healy’s principles of great visualizations or Alberto Cairo’s five qualities of great visualizations?  Upload the following outputs to iCollege:\n A PDF or Word file of your memo with your final code and graphic embedded in it.1 This means you’ll need to do all your coding in an R Markdown file and embed your code in chunks. A standalone PNG version of your graphic. Use ggsave(plot_name, filename = \"output/blah.png\", width = XX, height = XX) A standalone PDF version of your graphic. Use ggsave(plot_name, filename = \"output/blah.pdf\", width = XX, height = XX)   You will be graded based on completion using the standard ✓ system, but I’ll provide comments on how you use R and ggplot2, how well you apply the principles of CRAP, The Truthful Art, and Effective Data Visualization, and how appropriate the graph is for the data and the story you’re telling. I will use this rubric to make comments and provide you with a simulated grade.\n  mini-project-1-rubric.pdf  For this assignment, I am less concerned with detailed graphic design principles—select appropriate colors, change fonts if you’re brave, and choose a nice ggplot theme and make some adjustments like moving the legend around (theme(legend.position = \"bottom\")).\nThe assignment is due by 11:59 PM on Friday, May 226.\nPlease seek out help when you need it! You know enough R (and have enough examples of code from class and your readings) to be able to do this. Your project has to be turned in individually, and your visualization should be your own (i.e. if you work with others, don’t all turn in the same graph), but you should work with others! Reach out to me for help too—I’m here to help!\nYou can do this, and you’ll feel like a budding dataviz witch/wizard when you’re done.\n Starter code I’ve provided some starter code below. A couple comments about it:\n By default, read_csv() treats cells that are empty or “NA” as missing values. This rat dataset uses “N/A” to mark missing values, so we need to add that as a possible marker of missingness (hence na = c(\"\", \"NA\", \"N/A\")) To make life easier, I’ve renamed some of the key variables you might work with. You can rename others if you want. I’ve also created a few date-related variables (sighting_year, sighting_month, sighting_day, and sighting_weekday). You don’t have to use them, but they’re there if you need them. The functions that create these, like year() and wday() are part of the lubridate library. The date/time variables are formatted like 04/03/2017 12:00:00 AM, which R is not able to automatically parse as a date when reading the CSV file. You can use the mdy_hms() function in the lubridate library to parse dates that are structured as “month-day-year-hour-minute”. There are also a bunch of other iterations of this function, like ymd(), dmy(), etc., for other date formats. There’s one row with an unspecified borough, so I filter that out.  library(tidyverse) library(lubridate) rats_raw \u0026lt;- read_csv(\u0026quot;data/Rat_Sightings.csv\u0026quot;, na = c(\u0026quot;\u0026quot;, \u0026quot;NA\u0026quot;, \u0026quot;N/A\u0026quot;)) # If you get an error that says \u0026quot;All formats failed to parse. No formats # found\u0026quot;, it\u0026#39;s because the mdy_hms function couldn\u0026#39;t parse the date. The date # variable *should* be in this format: \u0026quot;04/03/2017 12:00:00 AM\u0026quot;, but in some # rare instances, it might load without the seconds as \u0026quot;04/03/2017 12:00 AM\u0026quot;. # If there are no seconds, use mdy_hm() instead of mdy_hms(). rats_clean \u0026lt;- rats_raw %\u0026gt;% rename(created_date = `Created Date`, location_type = `Location Type`, borough = Borough) %\u0026gt;% mutate(created_date = mdy_hms(created_date)) %\u0026gt;% mutate(sighting_year = year(created_date), sighting_month = month(created_date), sighting_day = day(created_date), sighting_weekday = wday(created_date, label = TRUE, abbr = FALSE)) %\u0026gt;% filter(borough != \u0026quot;Unspecified\u0026quot;) You’ll summarize the data with functions from dplyr, including stuff like count(), arrange(), filter(), group_by(), summarize(), and mutate(). Here are some examples of ways to summarize the data:\n# See the count of rat sightings by weekday rats_clean %\u0026gt;% count(sighting_weekday) # Assign a summarized data frame to an object to use it in a plot rats_by_weekday \u0026lt;- rats_clean %\u0026gt;% count(sighting_weekday, sighting_year) ggplot(rats_by_weekday, aes(x = fct_rev(sighting_weekday), y = n)) + geom_col() + coord_flip() + facet_wrap(~ sighting_year) # See the count of rat sightings by weekday and borough rats_clean %\u0026gt;% count(sighting_weekday, borough, sighting_year) # An alternative to count() is to specify the groups with group_by() and then # be explicit about how you\u0026#39;re summarizing the groups, such as calculating the # mean, standard deviation, or number of observations (we do that here with # `n()`). rats_clean %\u0026gt;% group_by(sighting_weekday, borough) %\u0026gt;% summarize(n = n())   You can approach this in a couple different ways—you can write the memo and then include the full figure and code at the end, similar to this blog post, or you can write the memo in an incremental way, describing the different steps of creating the figure, ultimately arriving at a clean final figure, like this blog post.↩︎\n   ","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"9b28187cb20ce4d6b54b6b87a6c394fc","permalink":"https://uvaDS8104.github.io/assignment/01-mini-project/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/assignment/01-mini-project/","section":"assignment","summary":"Instructions Starter code   New York City is full of urban wildlife, and rats are one of the city’s most infamous animal mascots. Rats in NYC are plentiful, but they also deliver food, so they’re useful too.\n  NYC keeps incredibly detailed data regarding animal sightings, including rats, and it makes this data publicly available.\nFor this first mini project, you will use R and ggplot2 to tell an interesting story hidden in the data.","tags":null,"title":"Mini project 1","type":"docs"},{"authors":null,"categories":null,"content":"   Task 1: Make an RStudio Project Task 2: Make an R Markdown file with a plot in it   Task 1: Make an RStudio Project Use either RStudio.cloud or RStudio on your computer (preferably RStudio on your computer! Follow these instructions to get started!) to create a new RStudio Project.\n Create a folder named “data” in the project folder you just made.\n Download this CSV file and place it in that folder:\n  cars.csv  In RStudio, go to “File” \u0026gt; “New File…” \u0026gt; “R Markdown…” and click “OK” in the dialog without changing anything.\n Delete all the placeholder text in that new file and replace it with this:\n--- title: \u0026quot;Exercise 1\u0026quot; author: \u0026quot;Put your name here\u0026quot; output: html_document --- # Reflection Replace this text with your reflection # My first plot ```{r load-libraries-data, warning=FALSE, message=FALSE} library(tidyverse) cars \u0026lt;- read_csv(\u0026quot;data/cars.csv\u0026quot;) ``` Replace this line with a code chunk and use it to create a plot.  Save the R Markdown file with some sort of name (without any spaces!)\n Your project folder should look something like this:\n   Task 2: Make an R Markdown file with a plot in it Add your reading reflection to the appropriate place in the R Markdown file. You can type directly in RStudio if you want (though there’s no spell checker), or you can type it in Word or Google Docs and then paste it into RStudio.\n Remove the text that says “Replace this line with a code chunk” and insert a new R code chunk. Either type ctrl + alt + i on Windows, or ⌘ + ⌥ + i on macOS, or use the “Insert Chunk” menu:\n Use ggplot() to create a scatterplot using the mpg dataset. Use whatever variables you want. Type the code to create the plot in the new empty chunk.\n Knit your document as a Word file (or PDF if you’re brave and installed LaTeX). Use the “Knit” menu:\n Upload the knitted document to iCollege.\n 🎉 Party! 🎉\n  You’ll be doing this same process for all your future exercises. Each exercise will involve an R Markdown file. You can either create a new RStudio Project directory for all your work:\nOr you can create individual projects for each assignment and mini-project:\n  ","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"fcce0f7ada10fbf30daa67e2ac98e630","permalink":"https://uvaDS8104.github.io/assignment/01-exercise/","publishdate":"2020-05-11T00:00:00Z","relpermalink":"/assignment/01-exercise/","section":"assignment","summary":"Task 1: Make an RStudio Project Task 2: Make an R Markdown file with a plot in it   Task 1: Make an RStudio Project Use either RStudio.cloud or RStudio on your computer (preferably RStudio on your computer! Follow these instructions to get started!) to create a new RStudio Project.\n Create a folder named “data” in the project folder you just made.\n Download this CSV file and place it in that folder:","tags":null,"title":"Introduction to R and the tidyverse","type":"docs"},{"authors":null,"categories":null,"content":"   Basic process for working with RStudio   Basic process for working with RStudio For this example, I’m going to create a new RStudio project, download some data, put the data in the project, and make a graph of it using R Markdown. You’ll follow this same process any time you start a new project or exercise.\nTo follow along, download this CSV file here (you may need to right click on it and select “Save As…”):\n  gapminder.csv  Here’s a video walkthrough of how to get started:\n   ","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"059bb398e999a9d10b388c3df2b5644f","permalink":"https://uvaDS8104.github.io/example/01-example/","publishdate":"2020-05-11T00:00:00Z","relpermalink":"/example/01-example/","section":"example","summary":"Basic process for working with RStudio   Basic process for working with RStudio For this example, I’m going to create a new RStudio project, download some data, put the data in the project, and make a graph of it using R Markdown. You’ll follow this same process any time you start a new project or exercise.\nTo follow along, download this CSV file here (you may need to right click on it and select “Save As…”):","tags":null,"title":"Introduction to R and the tidyverse","type":"docs"},{"authors":null,"categories":null,"content":"   Part 1: The basics of R and dplyr Part 2: Getting familiar with RStudio Part 3: RStudio Projects Part 4: Getting familiar with R Markdown   Part 1: The basics of R and dplyr For the first part of today’s lesson, you need to work through a few of RStudio’s introductory primers. You’ll do these in your browser and type code and see results there.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the dplyr package.\nComplete these:\n The Basics  Visualization Basics Programming Basics  Work with Data  Working with Tibbles Isolating Data with dplyr Deriving Information with dplyr   The content from these primers comes from the (free and online!) book R for Data Science by Garrett Grolemund and Hadley Wickham. I highly recommend the book as a reference and for continuing to learn and use R in the future (like running regression models and other types of statistical analysis)\n Part 2: Getting familiar with RStudio The RStudio primers you just worked through are a great introduction to writing and running R code, but you typically won’t type code in a browser when you work with R. Instead, you’ll use a nicer programming environment like RStudio, which lets you type and save code in scripts, run code from those scripts, and see the output of that code, all in the same program.\nTo get familiar with RStudio, watch this video:\n   Part 3: RStudio Projects One of the most powerful and useful aspects of RStudio is its ability to manage projects.\nWhen you first open R, it is “pointed” at some folder on your computer, and anything you do will be relative to that folder. The technical term for this is a “working directory.”\nWhen you first open RStudio, look in the area right at the top of the Console pane to see your current working directory. Most likely you’ll see something cryptic: ~/\nThat tilde sign (~) is a shortcut that stands for your user directory. On Windows this is C:\\Users\\your_user_name\\; on macOS this is /Users/your_user_name/. With the working directory set to ~/, R is “pointed” at that folder, and anything you save will end up in that folder, and R will expect any data that you load to be there too.\nIt’s always best to point R at some other directory. If you don’t use RStudio, you need to manually set the working directory to where you want it with setwd(), and many R scripts in the wild include something like setwd(\"C:\\\\Users\\\\bill\\\\Desktop\\\\Important research project\") at the beginning to change the directory. THIS IS BAD THOUGH (see here for an explanation). If you ever move that directory somewhere else, or run the script on a different computer, or share the project with someone, the path will be wrong and nothing will run and you will be sad.\nThe best way to deal with working directories with RStudio is to use RStudio Projects. These are special files that RStudio creates for you that end in a .Rproj extension. When you open one of these special files, a new RStudio instance will open up and be pointed at the correct directory automatically. If you move the folder later or open it on a different computer, it will work just fine and you will not be sad.\nRead this super short chapter on RStudio projects.\n Part 4: Getting familiar with R Markdown To ensure that the analysis and graphics you make are reproducible, you’ll do the majority of your work in this class using R Markdown files.\nDo the following things:\nWatch this video:     Skim through the content at these pages:\n Using Markdown Using R Markdown How it Works Code Chunks Inline Code Markdown Basics (The R Markdown Reference Guide is super useful here.) Output Formats  Watch this video:\n     ","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"2248ef62e0fddbf88b2832cdafb38b9a","permalink":"https://uvaDS8104.github.io/lesson/01-lesson/","publishdate":"2020-05-11T00:00:00Z","relpermalink":"/lesson/01-lesson/","section":"lesson","summary":"Part 1: The basics of R and dplyr Part 2: Getting familiar with RStudio Part 3: RStudio Projects Part 4: Getting familiar with R Markdown   Part 1: The basics of R and dplyr For the first part of today’s lesson, you need to work through a few of RStudio’s introductory primers. You’ll do these in your browser and type code and see results there.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the dplyr package.","tags":null,"title":"Introduction to R and the tidyverse","type":"docs"},{"authors":null,"categories":null,"content":"   RStudio.cloud RStudio on your computer  Install R Install RStudio Install tidyverse Install tinytex    You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nRStudio.cloud R is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://rstudio.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you.\n RStudio on your computer RStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\nInstall R First you need to install R itself (the engine).\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\n Click on “Download R for XXX”, where XXX is either Mac or Windows:\n If you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is also 4.0.0) and download it.\n If you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n  Double click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\n If you use macOS, download and install XQuartz. You do not need to do this on Windows.\n   Install RStudio Next, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\n The website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n Double click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n  Double click on RStudio to run it (check your applications folder or start menu).\n Install tidyverse R packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n Install tinytex When you knit to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nHere’s how to install tinytex so you can knit to pretty PDFs:\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console. Run tinytex::install_tinytex() in the console. Wait for a bit while R downloads and installs everything you need. The end! You should now be able to knit to PDF.     It’s a goofy name, but CRAN is where most R packages—and R itself—lives.↩︎\n   ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"efb59c0882a965443ffcbafa3cd27ca6","permalink":"https://uvaDS8104.github.io/resource/install/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/resource/install/","section":"resource","summary":"RStudio.cloud RStudio on your computer  Install R Install RStudio Install tidyverse Install tinytex    You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.","tags":null,"title":"Installing R, RStudio, tidyverse, and tinytex","type":"docs"},{"authors":null,"categories":null,"content":"   Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based) Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes. ColourLovers: Like Facebook for color palettes. viridis: Percetually uniform color scales. Scientific Colour-Maps: Perceptually uniform color scales like viridis. Use them in R with scico. ColorBrewer: Sequential, diverging, and qualitative color palettes that take accessibility into account. Colorgorical: Create color palettes based on fancy mathematical rules for perceptual distance. Colorpicker for data: More fancy mathematical rules for color palettes (explanation). iWantHue: Yet another perceptual distance-based color palette builder. Photochrome: Word-based color pallettes. PolicyViz Design Color Tools: Large collection of useful color resources   Fonts  Google Fonts: Huge collection of free, well-made fonts. The Ultimate Collection of Google Font Pairings: A list of great, well-designed font pairings from all those fonts hosted by Google (for when you’re looking for good contrasting or complementary fonts).   Graphic assets Images  Use the Creative Commons filters on Google Images or Flickr Unsplash Pexels Pixabay StockSnap.io Burst freephotos.cc   Vectors  Noun Project: Thousands of free simple vector images aiconica: 1,000+ vector icons Vecteezy: Thousands of free vector images   Vectors, photos, videos, and other assets  Stockio    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"16fd04c4714e3d096bffcf19e6c524ca","permalink":"https://uvaDS8104.github.io/resource/design/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/design/","section":"resource","summary":"Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based) Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes. ColourLovers: Like Facebook for color palettes.","tags":null,"title":"Design","type":"docs"},{"authors":null,"categories":null,"content":"   File types Select the best file type   File types Recall from the last section of the lecture that you’ll typically work with one of two image file types: bitmap images and vector images.\nBitmaps store image information as tiny squares, or pixels. Specific files types compress these images in different ways: JPEG files smudge together groups of similarly colored pixels to save repetition, while PNG and GIF files look for fields of the exact same color.\nYou use bitmap images for things that go on the internet and when you place images in Word (technically modern versions of Word can handle some types of vector images, but that support isn’t universal yet).\nVector images, on the other hand, do not store image information as pixels. Instead, these use mathematical formulas to draw lines and curves and fill areas with specific colors. This makes them a little more complicated to draw and create, but it also means that you can scale them up or down infinitely—a vector image will look just as crisp on a postage stamp as it would on a billboard.\nHere are some general guidelines:\n If an image has lots of colors (like a photograph), you should use a bitmap file type designed for lots of colors, like JPEG. This is the case regardless of where the image will ultimately end up. If you’re putting it on the internet, it needs to be a JPEG. If you’re blowing it up to fit on a billboard, it will still need to be a JPEG (and you have to use a fancy super high quality camera to get a high enough resolution for that kind of expansion)\n If an image has a few colors and some text and is not a photograph and you’re using the image in Word or on the internet, you should use a bitmap file type designed for carefully compressing a few colors, like PNG.\n If an image has a few colors and some text and is not a photograph and you’re planning on using it in multiple sizes (like a logo), or using it in fancier production software like Adobe InDesign (for print) or Adobe After Effects (for video), you should use a vector file type like PDF or SVG.\n   Select the best file type Practice deciding what kind of file type you should use by looking at these images and choosing what you think works the best.\nPNG\nJPG\nPDF\n  function validate_form_1() {var x, text; var x = document.forms[\"form_1\"][\"answer_1\"].value;if (x == \"JPG\"){text = 'Correct! This is a photograph, so it should be a JPG. It might seem a little tricky since there are so few colors, but it still needs to be a JPG because the black paint on the brick is actually a range of thousands of different shades of black pixels.';} else {text = 'Not quite—this image has a lot of colors in it…';} document.getElementById('result_1').innerHTML = text; return false;}   PNG\nJPG\nPDF\n  function validate_form_2() {var x, text; var x = document.forms[\"form_2\"][\"answer_2\"].value;if (x == \"PNG\"|x == \"PDF\"){text = 'Correct! This is a logo with a few colors in it, so it’s vector-based. If you use a PDF of the logo, you can rescale it infinitely big or small. If you use a PNG, it will work nicely online.';} else {text = 'Not quite—this image doesn’t have a lot of colors in it…';} document.getElementById('result_2').innerHTML = text; return false;}   PNG\nJPG\nPDF\n  function validate_form_3() {var x, text; var x = document.forms[\"form_3\"][\"answer_3\"].value;if (x == \"PNG\"|x == \"PDF\"){text = 'Correct! This is a grpah with a few colors in it, so should be vector-based. If you’re using this in a fancy publication or report, use a PDF. If you’e using Word or HTML, use a PNG.';} else {text = 'Not quite—this image doesn’t have a lot of colors in it…';} document.getElementById('result_3').innerHTML = text; return false;}   PNG\nJPG\nPDF\n  function validate_form_4() {var x, text; var x = document.forms[\"form_4\"][\"answer_4\"].value;if (x == \"JPG\"){text = 'Correct! This has a ton of colors in it and is mostly a photograph. You may have been thrown off by the text in the bottom section, or the stylized shapes of the Millennium Falcon’s windows at the top. Those shapes and the text are both vector-based, but because the majority of the image is a photogrpah, it still needs to be saved as a JPG. To keep the text nice and crisp, it needs to be exported at a high resolution.';} else {text = 'Not quite—this image has a lot of colors in it…';} document.getElementById('result_4').innerHTML = text; return false;}   PNG\nJPG\nPDF\n  function validate_form_5() {var x, text; var x = document.forms[\"form_5\"][\"answer_5\"].value;if (x == \"PNG\"|x == \"PDF\"){text = 'Correct! Even though this is very colorful, it should be a PNG or PDF, since it’s vector-based and not a photograph. ';} else {text = 'Not quite—this image doesn’t have a lot of colors in it…';} document.getElementById('result_5').innerHTML = text; return false;}   PNG\nJPG\nPDF\n  function validate_form_6() {var x, text; var x = document.forms[\"form_6\"][\"answer_6\"].value;if (x == \"JPG\"){text = 'Correct! This is a photograph and should be a JPG.';} else {text = 'Not quite—this image has a lot of colors in it…';} document.getElementById('result_6').innerHTML = text; return false;}    ","date":1589241600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"911ebe9376618b75c6ca9ac02110b8b9","permalink":"https://uvaDS8104.github.io/lesson/02-lesson/","publishdate":"2020-05-12T00:00:00Z","relpermalink":"/lesson/02-lesson/","section":"lesson","summary":"File types Select the best file type   File types Recall from the last section of the lecture that you’ll typically work with one of two image file types: bitmap images and vector images.\nBitmaps store image information as tiny squares, or pixels. Specific files types compress these images in different ways: JPEG files smudge together groups of similarly colored pixels to save repetition, while PNG and GIF files look for fields of the exact same color.","tags":null,"title":"Graphic design","type":"docs"},{"authors":null,"categories":null,"content":"   Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting     Type… …or… …to get    Some text in a paragraph. More text in the next paragraph. Always use empty lines between paragraphs.  Some text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n  *Italic* _Italic_ Italic  **Bold** __Bold__ Bold  # Heading 1  Heading 1   ## Heading 2  Heading 2   ### Heading 3  Heading 3   (Go up to heading level 6 with ######)    [Link text](http://www.example.com)  Link text  ![Image caption](/path/to/image.png)    `Inline code` with backticks  Inline code with backticks  \u0026gt; Blockquote   Blockquote\n  - Things in - an unordered - list * Things in * an unordered * list  Things in an unordered list   1. Things in 2. an ordered 3. list 1) Things in 2) an ordered 3) list Things in an ordered list   Horizontal line --- Horizontal line *** Horizontal line\n     Math Markdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here.\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n    Type… …to get    Based on the DAG, the regression model for estimating the effect of education on wages is $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, or $\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon$. Based on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\).    To put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was an important part of high school math: $$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ But now we just use computers to solve for $x$. …to get…\n The quadratic equation was an important part of high school math:\n\\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\nBut now we just use computers to solve for \\(x\\).\n Because dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs $5.75 and this other costs $40”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”.\n Tables There are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like pander (use pandoc.table()) or knitr (use kable()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\n Right Left Center Default ------- ------ ---------- ------- 12 12 12 12 123 123 123 123 1 1 1 1 Table: Caption goes here …to get…\n Caption goes here  Right Left Center Default    12 12 12 12  123 123 123 123  1 1 1 1    For pipe tables, type…\n| Right | Left | Default | Center | |------:|:-----|---------|:------:| | 12 | 12 | 12 | 12 | | 123 | 123 | 123 | 123 | | 1 | 1 | 1 | 1 | Table: Caption goes here …to get…\n Caption goes here  Right Left Default Center    12 12 12 12  123 123 123 123  1 1 1 1     Footnotes There are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags]. [^1]: This is a note. [^note-on-dags]: DAGs are neat. And here\u0026#39;s more of the document. …to get…\n Here is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n  This is a note.↩︎   DAGs are neat.↩︎     You can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!] …to get…\n Causal inference is neat.1\n  But it can be hard too!↩︎      Front matter You can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; --- You can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n--- title: \u0026quot;My cool title: a subtitle\u0026quot; --- If you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n--- title: \u0026#39;An evaluation of \u0026quot;scare quotes\u0026quot;\u0026#39; ---  Citations One of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\nAdd a bibliography: entry to the YAML metadata:\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib --- Choose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib csl: \u0026quot;https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\u0026quot; --- Some of the most common CSLs are:\n Chicago author-date Chicago note-bibliography Chicago full note-bibliography (no shortened notes or ibids) APA 7th edition MLA 8th edition  Cite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n    Type… …to get…    Causal inference is neat [@Rohrer:2018; @AngristPischke:2015]. Causal inference is neat (Rohrer 2018; Angrist and Pischke 2015).  Causal inference is neat [see @Rohrer:2018, p. 34; also @AngristPischke:2015, chapter 1]. Causal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1).  Angrist and Pischke say causal inference is neat [-@AngristPischke:2015; see also @Rohrer:2018]. Angrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).  @AngristPischke:2015 [chapter 1] say causal inference is neat, and @Rohrer:2018 agrees. Angrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees.    After compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n Angrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n   Other references These websites have additional details and examples and practice tools:\n CommonMark’s Markdown tutorial: A quick interactive Markdown tutorial. Markdown tutorial: Another interactive tutorial to practice using Markdown. Markdown cheatsheet: Useful one-page reminder of Markdown syntax. The Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown.   ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"dcf6a5ae191a1cca4f4c8ff8ac114538","permalink":"https://uvaDS8104.github.io/resource/markdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/resource/markdown/","section":"resource","summary":"Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting     Type… …or… …to get    Some text in a paragraph.","tags":null,"title":"Using Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  The Stories Behind a Line Australia as 100 people: You can make something like this with d3 and the potato project. Marrying Later, Staying Single Longer   How to select the appropriate chart type Many people have created many useful tools for selecting the correct chart type for a given dataset or question. Here are some of the best:\n The Data Visualisation Catalogue: Descriptions, explanations, examples, and tools for creating 60 different types of visualizations. The Data Viz Project: Descriptions and examples for 150 different types of visualizations. Also allows you to search by data shape and chart function (comparison, correlation, distribution, geographical, part to whole, trend over time, etc.). From Data to Viz: A decision tree for dozens of chart types with links to R and Python code. The Chartmaker Directory: Examples of how to create 51 different types of visualizations in 31 different software packages, including Excel, Tableau, and R. R Graph Catalog: R code for 124 ggplot graphs. Emery’s Essentials: Descriptions and examples of 26 different chart types.   General resources  Storytelling with Data: Blog and site full of resources by Cole Nussbaumer Knaflic. Ann K. Emery’s blog: Blog and tutorials by Ann Emery. Evergreen Data: Helful resources by Stephanie Evergreen. PolicyViz: Regular podcast and site full of helpful resources by Jon Schwabisch. Visualising Data: Fantastic collection of visualization resources, articles, and tutorials by Andy Kirk. Info We Trust: Detailed explorations of visualizations by RJ Andrews, including a beautiful visual history of the field. FlowingData: Blog by Nathan Yau. Information is Beautiful: Blog by David McCandless. Junk Charts: Blog by Kaiser Fung. WTF Visualizations: Visualizations that make you ask “wtf?” The Data Visualization Checklist: A helpful set of criteria for grading the effectiveness of a graphic. Data Literacy Starter Kit: Compilation of resources to become data literate by Laura Calloway. Seeing Data: A series of research projects about perceptions and visualizations.   Visualization in Excel  How to Build Data Visualizations in Excel: Detailed tutorials for creating 14 different visualizations in Excel. Ann Emery’s tutorials: Fantastic series of tutorials for creating charts in Excel.   Visualization in Tableau Because it is focused entirely on visualization (and because it’s a well-supported commercial product), Tableau has a phenomenal library of tutorials and training videos. There’s a helpful collections of videos here, as well.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"ca403ba352e0871f06b445d2470037b3","permalink":"https://uvaDS8104.github.io/resource/visualization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/visualization/","section":"resource","summary":"Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  The Stories Behind a Line Australia as 100 people: You can make something like this with d3 and the potato project. Marrying Later, Staying Single Longer   How to select the appropriate chart type Many people have created many useful tools for selecting the correct chart type for a given dataset or question.","tags":null,"title":"Visualization","type":"docs"},{"authors":null,"categories":null,"content":"   Data from the internet  Nonprofit management Federal, state, and local government management Business management  Instructions Final deliverables Past examples  Travel runs in Yellowstone Firefighter fatalities Scripture use by The Killers Utah nonprofits Buckethead    You made it to the end of our whirlwind tour of data visualization principles! Congratulations!\nNow you get to show off all the tools you learned with a beautiful, truthful, narrative visualization.\nFor your final project, you will take a dataset, explore it, tinker with it, and tell a nuanced story about it using at least three graphs.\nI want this project to be as useful for you and your future career as possible—you’ll hopefully want to show off your final project in a portfolio or during job interviews.\nAccordingly, you have some choice in what data you can use for this project. I’ve found several different high-quality datasets online related to the core MPA/MPP tracks. You do not have to choose a dataset in your given field (especially if you’re not an MPA or MPP student!) Choose whatever one you are most interested in or will have the most fun with.\nData from the internet Go to this list of data sources and find something interesting! The things in the “Data is Plural” newsletter are often especially interesting and fun. Here are some different high-quality datasets that students have worked with before:\nNonprofit management  U.S. Charities and Non-profits: All of the charities and nonprofits registered with the IRS. This is actually split into six separate files. You can combine them all into one massive national database with bind_rows(), or filter the data to include specific states (or a single state). It all depends on the story you’re telling. Source: IRS. Nonprofit Grants 2010 to 2016: Nonprofit grants made in the US as listed in Schedule I of the IRS 990 tax form between 2010 to 2016. Source: IRS.   Federal, state, and local government management  Deadly traffic accidents in the UK (2015): List of all traffic-related deaths in the UK in 2015. Source: data.gov.uk. Firefighter Fatalities in the United States: Name, rank, and cause of death for all firefighters killed since 2000. Source: FEMA. Federal Emergencies and Disasters, 1953–Present: Every federal emergency or disaster declared by the President of the United States since 1953. Source: FEMA. Global Terrorism Database (1970–2016): 170,000 terrorist attacks worldwide, 1970-2016. Source: National Consortium for the Study of Terrorism and Responses to Terrorism (START), University of Maryland. City of Austin 311 Unified Data: All 311 calls to the City of Austin since 2014. Source: City of Austin.   Business management  515K Hotel Reviews Data in Europe: 515,000 customer reviews and scoring of 1,493 luxury hotels across Europe. Source: Booking.com. Chase Bank Branch Deposits, 2010–2016: Records for every branch of Chase Bank in the United States. This dataset is not quite tidy and will require a little bit of reshaping with gather() or pivot_longer(), since there are individual columns of deposits per year. Source: Chase Bank.    Instructions Here’s what you’ll need to do:\nDownload a dataset and explore it. Many of these datasets are large and will not open (well) in Excel, so you’ll need to load the CSV file into R with read_csv(). Most of these datasets have nice categorical variables that you can use for grouping and summarizing, and many have time components too, so you can look at trends. Your past problem sets and in-class examples will come in handy here.\n Find a story in the data. Explore that story and make sure it’s true and insightful.\n Use R to create multiple graphs to tell the story. You can make as many graphs as you want, but you must use at least three different chart types (i.e. don’t just make three scatterplots or three maps).\n Export these figures as PDF files, place them in Adobe Illustrator (or InDesign or Gravit Designer or Inkscape), and make one combined graphic or handout where you tell the complete story. You have a lot of latitude in how you do this. You can make a graphic-heavy one-page handout. You can make something along the lines of the this, with one big graphic + smaller subgraphics + explanatory text. Just don’t make a goofy infographic. Whatever you do, the final figure must include all the graphics, must have some explanatory text to help summarize the narrative, and must be well designed.\n Export the final graphic from Illustrator as a PDF and a PNG.\n Write a memo using R Markdown to introduce, frame, and describe your story and figure. Use this template to get started. You should include the following in the memo:\n Executive summary Background information and summary of the data Explanation, description, and code for each individual figure Explanation and description for the final figure Final figure should be included as an image (remember ![Caption goes here](path/to/file.png))   Remember to follow R Markdown etiquette rules and style—don’t have it output extraneous messages or warnings, include summary tables in nice tables, adjust the dimensions for your figures, and remove the placeholder text that’s in the template already (i.e. I don’t want to see stuff like “Describe and show how you cleaned and reshaped the data” in the final report.)\nYou should download a full example of what a final project might look like (but don’t make your final combined visualization look exactly like this—show some creativity!)\n Final deliverables Upload the following files to iCollege:\nA memo introducing and describing your final graphic (see full instructions above) A standalone PDF of your graphic exported from Illustrator A standalone PNG of your graphic exported from Illustrator  No late work will be accepted for this project since it’s the last project and it counts as your final.\nI will use this rubric to grade the final product:\n  final-project-rubric.xlsx  I am happy to give feedback and help along the way—please don’t hesitate to get help! My goal is for you to have a beautiful graphic in the end that you’ll want to show off to all your friends, family, neighbors, employers, and strangers on the street—I’m not trying to trip you up or give you trick questions!\nAnd that’s it. You’re done! Go out into the world now and make beautiful, insightful, and truthful graphics.\nGo forth and make awesomeness.\n Past examples Download a full example of what a final project might look like.\nHere are some great examples of student projects from past versions of this class.\nTravel runs in Yellowstone  Project description  Final PDF  Final PNG\n\n Firefighter fatalities  Project description  Final PDF  Final PNG\n\n Scripture use by The Killers  Project description  Final PDF  Final PNG\n\n Utah nonprofits  Project description  Final PDF  Final PNG\n\n Buckethead  Project description  Final PDF  Final PNG\n\n  ","date":1591315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"8d16837a0c729f9c31150a71deaf1f1e","permalink":"https://uvaDS8104.github.io/assignment/final-project/","publishdate":"2020-06-05T00:00:00Z","relpermalink":"/assignment/final-project/","section":"assignment","summary":"Data from the internet  Nonprofit management Federal, state, and local government management Business management  Instructions Final deliverables Past examples  Travel runs in Yellowstone Firefighter fatalities Scripture use by The Killers Utah nonprofits Buckethead    You made it to the end of our whirlwind tour of data visualization principles! Congratulations!\nNow you get to show off all the tools you learned with a beautiful, truthful, narrative visualization.","tags":null,"title":"Final project","type":"docs"},{"authors":null,"categories":null,"content":"   Part 1: Data visualization with ggplot2 Part 2: Reshaping data with tidyr   Part 1: Data visualization with ggplot2 For the first part of today’s lesson, you need to work through RStudio’s introductory primers for ggplot2. You’ll do these in your browser and type code and see results there.\nIt seems like there are a lot, but they’re short and go fairly quickly (especially as you get the hang of the ggplot() syntax). Complete these:\n Visualize Data  Exploratory Data Analysis Bar Charts Histograms Boxplots and Counts Scatterplots Line plots Overplotting and Big Data Customize Your Plots    Part 2: Reshaping data with tidyr For the last part of today’s lesson, you’ll work through just one RStudio primer to learn how to use the tidyr package to reshape data from wide to long and back to wide.\nComplete this:\n Tidy Your Data  Reshape Data   Recent versions of tidyr have renamed these core functions: gather() is now pivot_longer() and spread() is now pivot_wider(). The syntax for these pivot_*() functions is slightly different from what it was in gather() and spread(), so you can’t just replace the names. Fortunately, both gather() and spread() still work and won’t go away for a while, so you can still use them as you learn about reshaping and tidying data. It would be worth learning how the newer pivot_*() functions work, eventually, though (see here for examples).\n  ","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"e88a62444161c21a7f4779be93acbf33","permalink":"https://uvaDS8104.github.io/lesson/03-lesson/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/lesson/03-lesson/","section":"lesson","summary":"Part 1: Data visualization with ggplot2 Part 2: Reshaping data with tidyr   Part 1: Data visualization with ggplot2 For the first part of today’s lesson, you need to work through RStudio’s introductory primers for ggplot2. You’ll do these in your browser and type code and see results there.\nIt seems like there are a lot, but they’re short and go fairly quickly (especially as you get the hang of the ggplot() syntax).","tags":null,"title":"Mapping data to graphics","type":"docs"},{"authors":null,"categories":null,"content":"   Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:\nKey terms  Document: A Markdown file where you type stuff\n Chunk: A piece of R code that is included in your document. It looks like this:\n```{r} # Code goes here ``` There must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\n Knit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows.\n   Add chunks There are three ways to insert chunks:\n Press ⌘⌥I on macOS or control + alt + I on Windows\n Click on the “Insert” button at the top of the editor window\n Manually type all the backticks and curly braces (don’t do this)\n   Chunk names You can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk} # Code goes here ```  Chunk options There are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE} # Code goes here ``` The most common chunk options are these:\n fig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures echo=FALSE: The code is not shown in the final document, but the results are message=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted warning=FALSE: Any warnings that R generates are omitted include=FALSE: The chunk still runs, but the code and results are not included in the final document  You can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:\n Inline chunks You can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE} avg_mpg \u0026lt;- mean(mtcars$mpg) ``` The average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon. … would knit into this:\n The average fuel efficiency for cars from 1974 was 20.1 miles per gallon.\n  Output formats You can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \u0026quot;My document\u0026quot; output: html_document: default pdf_document: default word_document: default You can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n--- title: \u0026quot;My document\u0026quot; author: \u0026quot;My name\u0026quot; date: \u0026quot;January 13, 2020\u0026quot; output: html_document: toc: yes fig_caption: yes fig_height: 8 fig_width: 10 pdf_document: latex_engine: xelatex # More modern PDF typesetting engine toc: yes word_document: toc: yes fig_caption: yes fig_height: 4 fig_width: 5 ---  ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"00c0b36df90b91640842af65d1311657","permalink":"https://uvaDS8104.github.io/resource/rmarkdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/resource/rmarkdown/","section":"resource","summary":"Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown.","tags":null,"title":"Using R Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   Learning R R in the wild   Learning R I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work in this class will deal with ggplot2, it’s often easier to just search for that instead of the letter “r” (e.g. “ggplot scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n R for Data Science: A free online book for learning the basics of R and the tidyverse. R and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things. Stat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online. STA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online. CSE 631: Principles \u0026amp; Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio.   R in the wild A popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish knitted HTML files directly to RPubs, but you can also post your output to a blog or other type of website.1 Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\nHere are some of the best examples I’ve come across:\n Text analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up) Bob Ross - Joy of Painting Bechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight. Sexism on the Silver Screen: Exploring film’s gender divide Comparison of Quentin Tarantino Movies by Box Office and the Bechdel Test Who came to vote in Utah’s caucuses? Health care indicators in Utah counties Song lyrics across the United States A decade (ish) of listening to Sigur Rós When is Tom peeping these days?: There are a also bunch of final projects from other R and data visualization classes here and here. Mapping Fall Foliage General (Attys) Distributions Disproving Approval    If you want to be really fancy, you can use blogdown, which makes a complete website with R Markdown files. That’s actually how this site is built (see the source code). You can build your own site with this tutorial.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"0f6270d48011ac62645a8455a86a24bf","permalink":"https://uvaDS8104.github.io/resource/r/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/r/","section":"resource","summary":"Learning R R in the wild   Learning R I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.","tags":null,"title":"R","type":"docs"},{"authors":null,"categories":null,"content":"   R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.\n Main style things to pay attention to for this class  Important note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty\u0026gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n Spacing  See the “Spacing” section in the tidyverse style guide.\n Put spaces after commas (like in regular English):\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg , cty \u0026gt; 10) filter(mpg ,cty \u0026gt; 10) filter(mpg,cty \u0026gt; 10) Put spaces around operators like +, -, \u0026gt;, =, etc.:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg, cty\u0026gt;10) filter(mpg, cty\u0026gt; 10) filter(mpg, cty \u0026gt;10) Don’t put spaces around parentheses that are parts of functions:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter (mpg, cty \u0026gt; 10) filter ( mpg, cty \u0026gt; 10) filter( mpg, cty \u0026gt; 10 )  Long lines  See the “Long lines” section in the tidyverse style guide.\n It’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” \u0026gt; “Global Options” \u0026gt; “Code” \u0026gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n# Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Bad filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;)) # Good filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;))  Pipes (%\u0026gt;%) and ggplot layers (+) Put each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n# Good ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad and won\u0026#39;t even work ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() Put each step in a dplyr pipeline on separate lines, with the %\u0026gt;% at the end of the line, indented with two spaces:\n# Good mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad and won\u0026#39;t even work mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy))  Comments  See the “Comments” section in the tidyverse style guide.\n Comments should start with a comment symbol and a single space: #\n# Good #Bad #Bad If the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group You can add extra spaces to get inline comments to align, if you want:\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group If the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” \u0026gt; “Reflow comment”\n# Good # Happy families are all alike; every unhappy family is unhappy in its own way. # Everything was in confusion in the Oblonskys’ house. The wife had discovered # that the husband was carrying on an intrigue with a French girl, who had been # a governess in their family, and she had announced to her husband that she # could not go on living in the same house with him. This position of affairs # had now lasted three days, and not only the husband and wife themselves, but # all the members of their family and household, were painfully conscious of it. # Bad # Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Though, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"f4734e734c67442efdc8d228e91ad766","permalink":"https://uvaDS8104.github.io/resource/style/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/style/","section":"resource","summary":"R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you’ll notice that only a few of those iterations (the first three) are easily readable.","tags":null,"title":"R style suggestions","type":"docs"},{"authors":null,"categories":null,"content":"   Manipulating data with dplyr  Filtering with filter() Adding new columns with mutate() Combining multiple verbs with pipes (%\u0026gt;%) Summarizing data by groups with group_by() %\u0026gt;% summarize() Selecting with select() Arranging data with arrange() That’s it!  Changing colors, shapes, and sizes, with scale_*()   When you visualize proportions with ggplot, you’ll typically go through a two-step process:\nSummarize the data with dplyr (typically with a combination of group_by() and summarize()) Plot the summarized data  Manipulating data with dplyr You had some experience with dplyr functions in the RStudio primers, but we’ll briefly review them here.\nThere are 6 important verbs that you’ll typically use when working with data:\n Extract rows/cases with filter() Extract columns/variables with select() Arrange/sort rows with arrange() Make new columns/variables with mutate() Make group summaries with group_by %\u0026gt;% summarize()  Every dplyr verb follows the same pattern. The first argument is always a data frame, and the function always returns a data frame:\nVERB(DATA_TO_TRANSFORM, STUFF_IT_DOES) Filtering with filter() The filter() function takes two arguments: a data frame to transform, and a set of tests. It will return each row for which the test is TRUE.\nThis code, for instance, will look at the gapminder dataset and return all rows where country is equal to “Denmark”:\nfilter(gapminder, country == \"Denmark\")  ## # A tibble: 12 x 6 ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Denmark Europe 1952 70.8 4334000 9692. ## 2 Denmark Europe 1957 71.8 4487831 11100. ## 3 Denmark Europe 1962 72.4 4646899 13583. ## 4 Denmark Europe 1967 73.0 4838800 15937. ## 5 Denmark Europe 1972 73.5 4991596 18866. ## 6 Denmark Europe 1977 74.7 5088419 20423. ## 7 Denmark Europe 1982 74.6 5117810 21688. ## 8 Denmark Europe 1987 74.8 5127024 25116. ## 9 Denmark Europe 1992 75.3 5171393 26407. ## 10 Denmark Europe 1997 76.1 5283663 29804. ## 11 Denmark Europe 2002 77.2 5374693 32167. ## 12 Denmark Europe 2007 78.3 5468120 35278.  Notice that there are two equal signs (==). This is because it’s a logical test, similar to greater than (\u0026gt;) or less than (\u0026lt;). When you use a single equal sign, you set an argument (like data = gapminder); when you use two, you are doing a test. There are lots of different ways to do logical tests:\n  Test Meaning    x \u0026lt; y Less than  x \u0026gt; y Greater than  x == y Equal to  x \u0026lt;= y Less than or equal to  x \u0026gt;= y Greater than or equal to  x != y Not equal to  x %in% y In (group membership)  is.na(x) Is missing  !is.na(x) Is not missing    Your turn: Use filter() and logical tests to show:\nThe data for Canada All data for countries in Oceania Rows where life expectancy is greater than 82    You can also use multiple conditions, and these will extract rows that meet every test. By default, if you separate the tests with a comma, R will consider this an “and” test and find rows that are both Denmark and greater than 2000.\nfilter(gapminder, country == \"Denmark\", year  2000)  ## # A tibble: 2 x 6 ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Denmark Europe 2002 77.2 5374693 32167. ## 2 Denmark Europe 2007 78.3 5468120 35278.  You can also use “or” with “|” and “not” with “!”:\n  Operator Meaning    a \u0026amp; b and  a | b or  !a not    Your turn: Use filter() and logical tests to show:\nCanada before 1970 Countries where life expectancy in 2007 is below 50 Countries where life expectancy in 2007 is below 50 and are not in Africa    Beware of some common mistakes! You can’t collapse multiple tests into one. Instead, use two separate tests:\n# This won\u0026#39;t work! filter(gapminder, 1960 \u0026lt; year \u0026lt; 1980) # This will work filter(gapminder, 1960 \u0026lt; year, year \u0026lt; 1980) Also, you can avoid stringing together lots of tests by using the %in% operator, which checks to see if a value is in a list of values.\n# This works, but is tedious filter(gapminder, country == \u0026quot;Mexico\u0026quot; | country == \u0026quot;Canada\u0026quot; | country == \u0026quot;United States\u0026quot;) # This is more concise and easier to add other countries later filter(gapminder, country %in% c(\u0026quot;Mexico\u0026quot;, \u0026quot;Canada\u0026quot;, \u0026quot;United States\u0026quot;))  Adding new columns with mutate() You create new columns with the mutate() function. You can create a single column like this:\nmutate(gapminder, gdp = gdpPercap * pop)  ## # A tibble: 1,704 x 7 ## country continent year lifeExp pop gdpPercap gdp ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. ## 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. ## 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. ## 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. ## 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. ## 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. ## 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. ## 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. ## 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. ## 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. ## # … with 1,694 more rows  And you can create multiple columns by including a comma-separated list of new columns to create:\nmutate(gapminder, gdp = gdpPercap * pop,\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;pop_mill = round(pop / 1000000))  ## # A tibble: 1,704 x 8 ## country continent year lifeExp pop gdpPercap gdp pop_mill ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. 8 ## 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. 9 ## 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. 10 ## 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. 12 ## 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. 13 ## 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. 15 ## 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. 13 ## 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. 14 ## 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. 16 ## 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. 22 ## # … with 1,694 more rows  You can also do conditional tests within mutate() using the ifelse() function. This works like the =IFELSE function in Excel. Feed the function three arguments: (1) a test, (2) the value if the test is true, and (3) the value if the test is false:\nifelse(TEST, VALUE_IF_TRUE, VALUE_IF_FALSE) We can create a new column that is a binary indicator for whether the country’s row is after 1960:\nmutate(gapminder, after_1960 = ifelse(year  1960, TRUE, FALSE))  ## # A tibble: 1,704 x 7 ## country continent year lifeExp pop gdpPercap after_1960 ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. FALSE ## 2 Afghanistan Asia 1957 30.3 9240934 821. FALSE ## 3 Afghanistan Asia 1962 32.0 10267083 853. TRUE ## 4 Afghanistan Asia 1967 34.0 11537966 836. TRUE ## 5 Afghanistan Asia 1972 36.1 13079460 740. TRUE ## 6 Afghanistan Asia 1977 38.4 14880372 786. TRUE ## 7 Afghanistan Asia 1982 39.9 12881816 978. TRUE ## 8 Afghanistan Asia 1987 40.8 13867957 852. TRUE ## 9 Afghanistan Asia 1992 41.7 16317921 649. TRUE ## 10 Afghanistan Asia 1997 41.8 22227415 635. TRUE ## # … with 1,694 more rows  We can also use text labels instead of TRUE and FALSE:\nmutate(gapminder, \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;after_1960 = ifelse(year  1960, \"After 1960\", \"Before 1960\"))  ## # A tibble: 1,704 x 7 ## country continent year lifeExp pop gdpPercap after_1960 ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. Before 1960 ## 2 Afghanistan Asia 1957 30.3 9240934 821. Before 1960 ## 3 Afghanistan Asia 1962 32.0 10267083 853. After 1960 ## 4 Afghanistan Asia 1967 34.0 11537966 836. After 1960 ## 5 Afghanistan Asia 1972 36.1 13079460 740. After 1960 ## 6 Afghanistan Asia 1977 38.4 14880372 786. After 1960 ## 7 Afghanistan Asia 1982 39.9 12881816 978. After 1960 ## 8 Afghanistan Asia 1987 40.8 13867957 852. After 1960 ## 9 Afghanistan Asia 1992 41.7 16317921 649. After 1960 ## 10 Afghanistan Asia 1997 41.8 22227415 635. After 1960 ## # … with 1,694 more rows  Your turn: Use mutate() to:\nAdd an africa column that is TRUE if the country is on the African continent Add a column for logged GDP per capita Add an africa_asia column that says “Africa or Asia” if the country is in Africa or Asia, and “Not Africa or Asia” if it’s not     Combining multiple verbs with pipes (%\u0026gt;%) What if you want to filter to include only rows from 2002 and make a new column with the logged GDP per capita? Doing this requires both filter() and mutate(), so we need to find a way to use both at once.\nOne solution is to use intermediate variables for each step:\ngapminder_2002_filtered gapminder_2002_logged gapminder_2002_filtered, log_gdpPercap = log(gdpPercap)) That works fine, but your environment panel will start getting full of lots of intermediate data frames.\nAnother solution is to nest the functions inside each other. Remember that all dplyr functions return data frames, so you can feed the results of one into another:\nfilter(mutate(gapminder, log_gdpPercap = log(gdpPercap)), \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;year == 2002) That works too, but it gets really complicated once you have even more functions, and it’s hard to keep track of which function’s arguments go where. I’d avoid doing this entirely.\nOne really nice solution is to use a pipe, or %\u0026gt;%. The pipe takes an object on the left and passes it as the first argument of the function on the right.\n# gapminder will automatically get placed in the _____ spot gapminder %\u0026gt;% filter(_____, country == \u0026quot;Canada\u0026quot;) These two lines of code do the same thing:\nfilter(gapminder, country == \"Canada\")\ngapminder %% filter(country == \"Canada\") Using pipes, you can start with a data frame, pass it to one verb, then pass the output of that verb to the next verb, and so on. When reading any code with a %\u0026gt;%, it’s easiest to read the %\u0026gt;% as “and then”. This would read:\n Take the gapminder dataset and then filter it so that it only has rows from 2002 and then add a new column with the logged GDP per capita\n gapminder %\u0026gt;% filter(year == 2002) %\u0026gt;% mutate(log_gdpPercap = log(gdpPercap)) Here’s another way to think about pipes more conceptually. This isn’t valid R code, obviously, but imagine you’re going to take yourself, and then wake up, get out of bed, get dressed, and leave the house. Writing that whole process as nested functions would look like this:\nleave_house(get_dressed(get_out_of_bed(wake_up(me, time = \"8:00\"), side = \"correct\"), pants = TRUE, shirt = TRUE), car = TRUE, bike = FALSE) Instead of nesting everything, we can use pipes to chain these together. This would read\n Take myself, and then wake up at 8:00, and then get out of bed on the correct side, and then get dressed with pants and a shirt, and then leave the house in a car\n me %% \u0026nbsp;\u0026nbsp;wake_up(time = \"8:00\") %% \u0026nbsp;\u0026nbsp;get_out_of_bed(side = \"correct\") %% \u0026nbsp;\u0026nbsp;get_dressed(pants = TRUE, shirt = TRUE) %% \u0026nbsp;\u0026nbsp;leave_house(car = TRUE, bike = FALSE)  Summarizing data by groups with group_by() %\u0026gt;% summarize() The summarize() verb takes an entire frame and calculates summary information about it. For instance, this will find the average life expectancy for the whole gapminder data:\ngapminder %% summarize(mean_life = mean(lifeExp))  ## # A tibble: 1 x 1 ## mean_life ## \u0026lt;dbl\u0026gt; ## 1 59.5  You can also make multiple summary variables, just like mutate(), and it will return a column for each:\ngapminder %% summarize(mean_life = mean(lifeExp),\n\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;min_life = min(lifeExp))  ## # A tibble: 1 x 2 ## mean_life min_life ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 59.5 23.6  Your turn: Use summarize() to calculate:\nThe first (minimum) year in the gapminder dataset The last (maximum) year in the dataset The number of rows in the dataset (use the dplyr cheatsheet) The number of distinct countries in the dataset (use the dplyr cheatsheet)    Your turn: Use filter() and summarize() to calculate the median life expectancy on the African continent in 2007:\n  Notice that summarize() on its own summarizes the whole dataset, so you only get a single row back. These values are the averages and minimums for the entire data frame. If you group your data into separate subgroups, you can use summarize() to calculate summary statistics for each group. Do this with group_by().\nThe group_by() function puts rows into groups based on values in a column. If you run this:\ngapminder %% group_by(continent)  ## # A tibble: 1,704 x 6 ## # Groups: continent [5] ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. ## 7 Afghanistan Asia 1982 39.9 12881816 978. ## 8 Afghanistan Asia 1987 40.8 13867957 852. ## 9 Afghanistan Asia 1992 41.7 16317921 649. ## 10 Afghanistan Asia 1997 41.8 22227415 635. ## # … with 1,694 more rows  …you won’t see anything different! R has put the dataset into separate invisible groups behind the scenes, but you haven’t done anything with those groups, so nothing has really happened. If you do things with those groups with summarize(), though, group_by() becomes much more useful.\nFor instance, this will take the gapminder data frame, group it by continent, and then summarize it by calculating the number of distinct countries in each group. It will return one row for each group, so there should be a row for each continent:\ngapminder %\u0026gt;% group_by(continent) %\u0026gt;% summarize(n_countries = n_distinct(country))  ## # A tibble: 5 x 2 ## continent n_countries ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; ## 1 Africa 52 ## 2 Americas 25 ## 3 Asia 33 ## 4 Europe 30 ## 5 Oceania 2 You can calculate multiple summary statistics, as before:\ngapminder %\u0026gt;% group_by(continent) %\u0026gt;% summarize(n_countries = n_distinct(country), avg_life_exp = mean(lifeExp))  ## # A tibble: 5 x 3 ## continent n_countries avg_life_exp ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Africa 52 48.9 ## 2 Americas 25 64.7 ## 3 Asia 33 60.1 ## 4 Europe 30 71.9 ## 5 Oceania 2 74.3 Your turn: Find the minimum, maximum, and median life expectancy for each continent:\n  Your turn: Find the minimum, maximum, and median life expectancy for each continent in 2007 only:\n  Finally, you can group by multiple columns and R will create subgroups for every combination of the groups and return the number of rows of combinations. For instance, we can calculate the average life expectancy by both year and continent and we’ll get 60 rows, since there are 5 continents and 12 years (5 × 12 = 60):\ngapminder %\u0026gt;% group_by(continent, year) %\u0026gt;% summarize(avg_life_exp = mean(lifeExp))  ## # A tibble: 60 x 3 ## # Groups: continent [5] ## continent year avg_life_exp ## \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Africa 1952 39.1 ## 2 Africa 1957 41.3 ## 3 Africa 1962 43.3 ## 4 Africa 1967 45.3 ## 5 Africa 1972 47.5 ## 6 Africa 1977 49.6 ## 7 Africa 1982 51.6 ## 8 Africa 1987 53.3 ## 9 Africa 1992 53.6 ## 10 Africa 1997 53.6 ## # … with 50 more rows  Selecting with select() The last two verbs are far simpler than filter(), mutate(), and group_by() %\u0026gt;% summarize().\nYou can choose specific columns with the select() verb. This will only keep two columns: lifeExp and year:\ngapminder %% select(lifeExp, year)  ## # A tibble: 1,704 x 2 ## lifeExp year ## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 1 28.8 1952 ## 2 30.3 1957 ## 3 32.0 1962 ## 4 34.0 1967 ## 5 36.1 1972 ## 6 38.4 1977 ## 7 39.9 1982 ## 8 40.8 1987 ## 9 41.7 1992 ## 10 41.8 1997 ## # … with 1,694 more rows  You can remove specific columns by prefacing the column names with -, like -lifeExp:\ngapminder %% select(-lifeExp)  ## # A tibble: 1,704 x 5 ## country continent year pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Afghanistan Asia 1952 8425333 779. ## 2 Afghanistan Asia 1957 9240934 821. ## 3 Afghanistan Asia 1962 10267083 853. ## 4 Afghanistan Asia 1967 11537966 836. ## 5 Afghanistan Asia 1972 13079460 740. ## 6 Afghanistan Asia 1977 14880372 786. ## 7 Afghanistan Asia 1982 12881816 978. ## 8 Afghanistan Asia 1987 13867957 852. ## 9 Afghanistan Asia 1992 16317921 649. ## 10 Afghanistan Asia 1997 22227415 635. ## # … with 1,694 more rows  You can also rename columns using select(). Follow this pattern: select(old_name = new_name).\ngapminder %% select(year, country, life_expectancy = lifeExp)  ## # A tibble: 1,704 x 3 ## year country life_expectancy ## \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1952 Afghanistan 28.8 ## 2 1957 Afghanistan 30.3 ## 3 1962 Afghanistan 32.0 ## 4 1967 Afghanistan 34.0 ## 5 1972 Afghanistan 36.1 ## 6 1977 Afghanistan 38.4 ## 7 1982 Afghanistan 39.9 ## 8 1987 Afghanistan 40.8 ## 9 1992 Afghanistan 41.7 ## 10 1997 Afghanistan 41.8 ## # … with 1,694 more rows  Alternatively, there’s a special rename() verb that will, um, rename, while keeping all the other columns:\ngapminder %% rename(life_expectancy = lifeExp)  ## # A tibble: 1,704 x 6 ## country continent year life_expectancy pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. ## 7 Afghanistan Asia 1982 39.9 12881816 978. ## 8 Afghanistan Asia 1987 40.8 13867957 852. ## 9 Afghanistan Asia 1992 41.7 16317921 649. ## 10 Afghanistan Asia 1997 41.8 22227415 635. ## # … with 1,694 more rows   Arranging data with arrange() The arrange() verb sorts data. By default it sorts ascendingly, putting the lowest values first:\ngapminder %% arrange(lifeExp)  ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Rwanda Africa 1992 23.6 7290203 737. ## 2 Afghanistan Asia 1952 28.8 8425333 779. ## 3 Gambia Africa 1952 30 284320 485. ## 4 Angola Africa 1952 30.0 4232095 3521. ## 5 Sierra Leone Africa 1952 30.3 2143249 880. ## 6 Afghanistan Asia 1957 30.3 9240934 821. ## 7 Cambodia Asia 1977 31.2 6978607 525. ## 8 Mozambique Africa 1952 31.3 6446316 469. ## 9 Sierra Leone Africa 1957 31.6 2295678 1004. ## 10 Burkina Faso Africa 1952 32.0 4469979 543. ## # … with 1,694 more rows  You can reverse that by wrapping the column name with desc():\ngapminder %% arrange(desc(lifeExp))  ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Japan Asia 2007 82.6 127467972 31656. ## 2 Hong Kong, China Asia 2007 82.2 6980412 39725. ## 3 Japan Asia 2002 82 127065841 28605. ## 4 Iceland Europe 2007 81.8 301931 36181. ## 5 Switzerland Europe 2007 81.7 7554661 37506. ## 6 Hong Kong, China Asia 2002 81.5 6762476 30209. ## 7 Australia Oceania 2007 81.2 20434176 34435. ## 8 Spain Europe 2007 80.9 40448191 28821. ## 9 Sweden Europe 2007 80.9 9031088 33860. ## 10 Israel Asia 2007 80.7 6426679 25523. ## # … with 1,694 more rows  You can sort by multiple columns by specifying them in a comma separated list. For example, we can sort by continent and then sort by life expectancy within the continents:\ngapminder %% \u0026nbsp;\u0026nbsp;arrange(continent, desc(lifeExp))  ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Reunion Africa 2007 76.4 798094 7670. ## 2 Reunion Africa 2002 75.7 743981 6316. ## 3 Reunion Africa 1997 74.8 684810 6072. ## 4 Libya Africa 2007 74.0 6036914 12057. ## 5 Tunisia Africa 2007 73.9 10276158 7093. ## 6 Reunion Africa 1992 73.6 622191 6101. ## 7 Tunisia Africa 2002 73.0 9770575 5723. ## 8 Mauritius Africa 2007 72.8 1250882 10957. ## 9 Libya Africa 2002 72.7 5368585 9535. ## 10 Algeria Africa 2007 72.3 33333216 6223. ## # … with 1,694 more rows   That’s it! Those are the main verbs you’ll deal with in this class. There are dozens of other really useful ones—check out the dplyr and tidyr cheat sheet for examples.\n  Changing colors, shapes, and sizes, with scale_*() Recall from session 3 that the grammar of graphics uses a set of layers to define elements of plots:\nIn tomorrow’s session, you’ll learn all about the Theme layer. Here we’ll briefly cover the Scales layer, which we use for changing aspects of the different aesthetics, like using logged axes or changing colors or shapes.\nAll the functions that deal with scales conveniently follow the same naming pattern:\nscale_AESTHETIC_DETAILS() Here are some common scale functions:\nscale_x_continuous()\nscale_y_reverse()\nscale_color_viridis_c()\nscale_shape_manual(values = c(19, 13, 15))\nscale_fill_manual(values = c(\"red\", \"orange\", \"blue\")) You can see a list of all of the possible scale functions here, and you should reference that documentation (and the excellent examples) often when working with these functions.\nAs long as you have mapped a variable to an aesthetic with aes(), you can use the scale_*() functions to deal with it. For instance, in this ggplot, we have mapped variables to x, y, and fill, which means we can use those corresponding scale functions to manipulate how those aesthetics are shown. Here we reverse the y-axis (ew, don’t really do this), and we use a discrete viridis color palette:\ncontinent_counts \u0026lt;- gapminder %\u0026gt;% group_by(continent) %\u0026gt;% summarize(countries = n_distinct(country)) ggplot(continent_counts, aes(x = continent, y = countries, fill = continent)) + geom_col() + scale_y_reverse() + # lol this is bad; don\u0026#39;t do it in real life scale_fill_viridis_d() You can also use different arguments in the scale functions—again, check the documentation for examples. For instance, if we want to use the plasma palette from the viridis package, we can set that as an option:\nggplot(continent_counts, aes(x = continent, y = countries, fill = continent)) + geom_col() + scale_fill_viridis_d(option = \u0026quot;plasma\u0026quot;) That yellow might be too bright and hard to see, so we can tell ggplot to not use the full range of the palette, ending at 90% of the range instead:\nggplot(continent_counts, aes(x = continent, y = countries, fill = continent)) + geom_col() + scale_fill_viridis_d(option = \u0026quot;plasma\u0026quot;, end = 0.9) Instead of letting R calculate the colors from a general palette, you can also specify your own colors with scale_fill_manual() and feeding it a list of values—generally as hex codes or a name from a list of built-in R colors:\nggplot(continent_counts, aes(x = continent, y = countries, fill = continent)) + geom_col() + scale_fill_manual(values = c(\u0026quot;chartreuse4\u0026quot;, \u0026quot;cornsilk4\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;#fc03b6\u0026quot;, \u0026quot;#5c47d6\u0026quot;)) Scale functions also work for other aesthetics like shape or color or size. For instance, consider this plot, which has all three:\ngapminder_2007 \u0026lt;- gapminder %\u0026gt;% filter(year == 2007) ggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10() We can change the colors of the points with scale_color_*():\nggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10() + scale_color_manual(values = c(\u0026quot;chartreuse4\u0026quot;, \u0026quot;cornsilk4\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;#fc03b6\u0026quot;, \u0026quot;#5c47d6\u0026quot;)) We can change the shapes with scale_shape_*(). If you run ?pch in your console or search for pch in the help, you can see all the possible shapes.\nggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10() + scale_shape_manual(values = c(12, 9, 17, 19, 15)) You can change the size with scale_size_*(). Here we make it so the smallest possible size is 1 and the largest is 15:\nggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10() + scale_size_continuous(range = c(1, 15)) We can even do all three at once:\nggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10() + scale_color_manual(values = c(\u0026quot;chartreuse4\u0026quot;, \u0026quot;cornsilk4\u0026quot;, \u0026quot;black\u0026quot;, \u0026quot;#fc03b6\u0026quot;, \u0026quot;#5c47d6\u0026quot;)) + scale_shape_manual(values = c(12, 9, 17, 19, 15)) + scale_size_continuous(range = c(1, 15)) Phew. That’s ugly.\nOne last thing we can do with scales is format how they show up on the plot. Notice how the population legend uses scientific notation like 2.50e+08. This means you need to move the decimal point 8 places to the right, making it 250000000. Leaving it in scientific notation isn’t great because it makes it really hard to read and interpret.\nIf you load the scales library (which is installed as part of tidyverse but isn’t automatically loaded), you can use some neat helper functions to reformat the text that shows up in plots. For instance, we can make it so population is formatted as a number with commas every 3 numbers, and the x-axis is formatted as dollars:\nlibrary(scales) ggplot(gapminder_2007, aes(x = gdpPercap, y = lifeExp, color = continent, shape = continent, size = pop)) + geom_point() + scale_x_log10(labels = dollar) + scale_size_continuous(labels = comma) Check the documentation for scales for details about all the labelling functions it has, including dates, percentages, p-values, LaTeX math, etc.\n ","date":1589414400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"5a003ab3247913ac8f1034d05b4692ee","permalink":"https://uvaDS8104.github.io/lesson/04-lesson/","publishdate":"2020-05-14T00:00:00Z","relpermalink":"/lesson/04-lesson/","section":"lesson","summary":"Manipulating data with dplyr  Filtering with filter() Adding new columns with mutate() Combining multiple verbs with pipes (%\u0026gt;%) Summarizing data by groups with group_by() %\u0026gt;% summarize() Selecting with select() Arranging data with arrange() That’s it!  Changing colors, shapes, and sizes, with scale_*()   When you visualize proportions with ggplot, you’ll typically go through a two-step process:\nSummarize the data with dplyr (typically with a combination of group_by() and summarize()) Plot the summarized data  Manipulating data with dplyr You had some experience with dplyr functions in the RStudio primers, but we’ll briefly review them here.","tags":null,"title":"Amounts and proportions","type":"docs"},{"authors":null,"categories":null,"content":"  Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.\nUnzipping files on macOS is trivial, but unzipping files on Windows can mess you up if you don’t pay careful attention. Here’s a helpful guide to unzipping files on both macOS and Windows.\nUnzipping files on macOS Double click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started.\n Unzipping files on Windows tl;dr: Right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This can be is incredibly confusing! Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top, and there’s a “Ratio” column that shows how much each file is compressed.\nIt is very tempting to try to open files from this view. However, if you do, things will break and you won’t be able to correctly work with any of the files in the zipped folder. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\nYou most likely won’t be able to open any data files or save anything, which will be frustrating.\nInstead, you need to right click on the .zip file and select “Extract All…”:\nThen choose where you want to unzip all the files and click on “Extract”\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work.\n ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"c14c352fd4c4ab8c12a3cd60b30b9d8c","permalink":"https://uvaDS8104.github.io/resource/unzipping/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/resource/unzipping/","section":"resource","summary":"Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.","tags":null,"title":"Unzipping files","type":"docs"},{"authors":null,"categories":null,"content":"  There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\n Google Dataset Search: Google indexes thousands of public datasets; search for them here.\n Kaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n 360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\n US City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\n Political science and economics datasets: There’s a wealth of data available for political science- and economics-related topics:\n François Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities. Thomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.). Erik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"2210aa8aeb5724b04bdf63d813d61030","permalink":"https://uvaDS8104.github.io/resource/data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/data/","section":"resource","summary":"There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\n Google Dataset Search: Google indexes thousands of public datasets; search for them here.","tags":null,"title":"Data","type":"docs"},{"authors":null,"categories":null,"content":"   Complete ggplot themes Modifying plot elements with theme()  Deal with general plot elements Disable elements completely with element_blank() Deal with borders and backgrounds with element_rect() Deal with lines with element_line() Deal with text with element_text()  Important note about ordering Fonts Reusing themes Saving plots   Complete ggplot themes There are many built-in complete themes that have a good combination of all the different theme() options already set for you. By default, ggplot uses theme_gray() (also spelled theme_grey() for UK English; because the first developer of ggplot (Hadley Wickham) is from New Zealand, British spelling works throughout (e.g. you can use colour instead of color))\nYour turn: Add theme_minimal() to this plot:\n  Hopefully that was easy!\nIf you look at the documentation for the different theme functions, you’ll notice that there are a few optional arguments, like base_size and base_family. The base_size argument changes the base font size for the text in the plot, and it is 11 by default. Changing it to something like 20 will not make all the text in the plot be sized at 20—functions like theme_minimal() set the size of plot elements based on the base_size. For instance, in theme_minimal(), the plot title is set to be 120% of base_size, while the caption is 80%. Changing base_size will resize all the different elements accordingly.\nYour turn: Modify this plot to use theme_minimal() with a base size of 16:\n  Hopefully that was also fairly straightforward!\n Modifying plot elements with theme() Using a complete theme like theme_minimal() or theme_bw() is a great starting point for getting a nice, clean, well designed plot. You’ll often need to make adjustments to smaller, more specific parts of the plot though. To do this, you can use the theme() function.\ntheme() is a massive function and has perhaps the most possible arguments of any function in R. It is impossible to remember everything it can possibly do. Fortunately its documentation is incredible. Run ?theme in your R console to see the help page, or go to this page online.\nDeal with general plot elements A few arguments to theme() don’t use any special function—you can just specify settings with text like \"bottom\" or \"right\"\nYour turn: Look at the documentation for theme() online. Make this plot’s legend appear on the bottom instead of the left.\n   Disable elements completely with element_blank() Any plot element can be disabled by using element_blank(). For instance, if you want to remove the axis ticks, you can use theme(axis.ticks = element_blank()).\nYour turn: Look at the documentation for theme() online. Disable the panel grid in this plot.\n  You can also target more specific plot elements. You can specify something like axis.text, which applies to all axis text, or you can use axis.text.y to only target the text on the y-axis.\nYour turn: Look at the documentation for theme() online. Make the following changes to this plot:\n Disable the major panel grid for the x-axis Disable the minor panel grid for the x-axis Disable the minor panel grid for the y-axis.  You should only have three horizontal lines for the grid.\n  Almost every other plot element fits into one of three categories: a rectangle, a line, or text. Changing the settings on these elements requires specific functions that correspond to these categories.\n Deal with borders and backgrounds with element_rect() Things like the plot background or the panel background or the legend background are rectangles and can be manipulated with element_rect(). If you want the legend box to be yellow with a thin black border, you would use theme(legend.box.background = element_rect(fill = \"yellow\", color = \"black\", size = 1).\nYour turn: Look at the documentation for theme() and the documentation for element() online. Make the following changes to this plot:\n Fill the plot background with #F2D8CE Fill the panel background with #608BA6, and make the border #184759 with size = 5  This will be a fairly ugly plot.\n   Deal with lines with element_line() Things like the panel grid, tick marks, and axis lines are all lines and can be manipulated with element_line(). If you want the x-axis line to be a dotted orange like, you would use theme(axis.line.x = element_line(color = \"orange\", linetype = \"dotted\").\nYour turn: Look at the documentation for theme() and the documentation for element() online. Make the following changes to this plot:\n Make the major panel gridlines blue and dashed with size = 1  This will also be a fairly ugly plot.\n   Deal with text with element_text() Finally, anything with text can be manipulated with element_text(), and you can specify all sorts of things, including font family (family), font weight (face), color (color), horizontal justification (hjust), angle (angle), and a bunch of other options. If you want the x-axis text to be italicized and rotated at a 45º angle, you would use theme(axis.text.x = element_text(face = \"italic\", angle = 45)).\nYour turn: Look at the documentation for theme() and the documentation for element() online. Make the following changes to this plot:\n Make the y-axis text italic Make the plot title right aligned, bold, and colored with #8C7811 Make the plot subtitle right aligned      Important note about ordering Things like theme_grey() or theme_minimal() are really just collections of changes to theme(), so the order is important when using a complete theme. If you do something like this to turn off the gridlines in the plot panel:\nggplot(...) + geom_point(...) + theme(panel.grid = element_blank()) + theme_bw() …you’ll still have panel gridlines! That’s because theme_bw() turns them on, and you typed it after you turned it off. If you want to use both theme_bw() and remove the gridlines, you need to make sure any theme adjustments come after theme_bw():\nggplot(...) + geom_point(...) + theme_bw() + theme(panel.grid = element_blank())  Fonts You can use theme() to change the fonts as well, though sometimes it’s a little tricky to get R to see the fonts on your computer—especially if you use Windows. This detailed blog post explains how to work with custom fonts in ggplot and shows how to get it set up on Windows. It should Just Work™ on macOS.\nIn short, as long as you load the fonts correctly, you can specify different fonts either in a complete theme like theme_minimal(base_family = \"Comic Sans MS\") or in theme() like theme(plot.title = element_text(family = \"Papyrus\")).\n Reusing themes If you want to repeat specific theme settings throughout a document, you can save yourself a ton of typing by storing the results of theme() to an object and reusing it. For instance, suppose you want your plots to be based on theme_minimal, have right aligned title and subtitle text, have the legend at the bottom, and have no minor gridlines. You can save all of that into an object named my_neato_theme or something, and then reuse it:\nmy_neato_theme \u0026lt;- theme_minimal() + theme(plot.title = element_text(hjust = 1), plot.subtitle = element_text(hjust = 1), legend.position = \u0026quot;bottom\u0026quot;, panel.grid.minor = element_blank()) # Make one plot ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(size = 3) + labs(title = \u0026quot;Engine displacement and highway MPG\u0026quot;, subtitle = \u0026quot;Heavier cars get worse mileage\u0026quot;) + my_neato_theme # Make another plot ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = cty)) + geom_point(size = 3) + labs(title = \u0026quot;Engine displacement and highway MPG\u0026quot;, subtitle = \u0026quot;Points colored by city MPG\u0026quot;) + my_neato_theme  Saving plots So far, all your plots have ended up either in RStudio or in a knitted HTML, Word, or PDF document. But what if you want to save just the plot to your computer so you can send it out to the world?! You could take a screenshot, but that won’t provide the highest resolution, and that will only save the plot as a bitmap-based PNG, not an infinitely resizable vector-based PDF!\nFortunately it’s pretty easy to save a plot using the special ggsave() function. You can specify whatever dimensions you want and whatever file type you want and save the standalone plot to your computer. You should look at the documentation for ggsave() for complete details of all the different options and arguments it can take. Typically, you do something like this.\nFirst create a plot and store it as an object. We haven’t done that yet in this lesson—so far we’ve just run ggplot() and seen the output immediately. If you save the output of ggplot() to an object, you actually won’t see anything until you run the name of the object.\na_cool_plot \u0026lt;- ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point(size = 3) + labs(title = \u0026quot;Engine displacement and highway MPG\u0026quot;, subtitle = \u0026quot;Heavier cars get worse mileage\u0026quot;) # Make sure you run this so you can see the plot a_cool_plot Next you can feed your saved plot to ggsave() to save it. It will automatically determine how to save it based on the filename you provide. If you tell it to be something.png, R will make a PNG; if you tell it to be something.pdf, R will make a PDF, and so on. Common types are PDF, PNG, JPEG (ew though), SVG, TIFF, and others.\nYou can also save the plot as multiple files. I typically make PNG and PDF versions of any plots I export like so:\nggsave(filename = \u0026quot;a_cool_plot.pdf\u0026quot;, plot = a_cool_plot, width = 6, height = 4.5, units = \u0026quot;in\u0026quot;) ggsave(filename = \u0026quot;a_cool_plot.png\u0026quot;, plot = a_cool_plot, width = 6, height = 4.5, units = \u0026quot;in\u0026quot;) From a file management perspective, it often makes sense to store all your output in a separate folder in your project, like output or figures or something. If you want to put saved images in a subfolder, include the name in the file name:\nggsave(filename = \u0026quot;figures/a_cool_plot.png\u0026quot;, plot = a_cool_plot, width = 6, height = 4.5, units = \u0026quot;in\u0026quot;) And finally, if you’re using custom fonts, you need to add one bit of wizardry to get the fonts to embed correctly in PDFs. This is something you just have to memorize or copy and paste a lot—if you want to know the full details, see this blog post. In short, R’s default PDF writer doesn’t know how to embed fonts and will panic if you make it try. R can use a different PDF-writing engine named Cairo that embeds fonts just fine, though, so you need to tell ggsave() to use it:\nggsave(filename = \u0026quot;figures/a_cool_plot.pdf\u0026quot;, plot = a_cool_plot, width = 6, height = 4.5, units = \u0026quot;in\u0026quot;, device = cairo_pdf)  ","date":1589500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"aa54929a56a6d237dc8692bd2c9cd024","permalink":"https://uvaDS8104.github.io/lesson/05-lesson/","publishdate":"2020-05-15T00:00:00Z","relpermalink":"/lesson/05-lesson/","section":"lesson","summary":"Complete ggplot themes Modifying plot elements with theme()  Deal with general plot elements Disable elements completely with element_blank() Deal with borders and backgrounds with element_rect() Deal with lines with element_line() Deal with text with element_text()  Important note about ordering Fonts Reusing themes Saving plots   Complete ggplot themes There are many built-in complete themes that have a good combination of all the different theme() options already set for you.","tags":null,"title":"Themes","type":"docs"},{"authors":null,"categories":null,"content":"  You can download a BibTeX file of all the non-web-based readings in the course:\n  references.bib  You can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"68be32a8da6a38dd54a9e724ab3904a0","permalink":"https://uvaDS8104.github.io/resource/citations/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/citations/","section":"resource","summary":"You can download a BibTeX file of all the non-web-based readings in the course:\n  references.bib  You can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online.","tags":null,"title":"Citations and bibliography","type":"docs"},{"authors":null,"categories":null,"content":"   Histograms Density plots Boxes, violins, and dots   Throughout this lesson, you’ll use the built-in mpg dataset to make histograms, density plots, box plots, violin plots, and other graphics that show uncertainty.\nSorry if mpg is getting repetitive! For short interactive things like this, it’s easier to use built-in and easy-to-load datasets like mpg and gapminder instead of loading CSV files, hence our constant reuse of the dataset. This is fairly normal too—the majority of examples in R help pages (and in peoples’ blog posts) use things like mpg orgapminder, or even iris, which measures the lengths and widths of a bunch of iris flowers in the 1930s (fun fact! I don’t like using iris because the data was originally used in an article in the Annals of Eugenics (😬) in 1936, and the data was collected to advance eugenics, and there’s no good reason to use data like that in 2020.)\nSo we work with cars instead of racist flower data.\nThe mpg dataset is available in R as soon as you load ggplot2 (or tidyverse). Yu don’t have to run read_csv() or anything—it’s just there in the background already.\nAs a reminder, here are the first few rows of the mpg dataset:\nhead(mpg) ## # A tibble: 6 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compa… ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compa… ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compa… ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compa… ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compa… ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compa… Histograms When working with histograms, you always need to think about the bin width. Histograms calculate the counts of rows within specific ranges of data, and the shape of the histogram will change depending on how wide or narrow these ranges (or bins, or buckets) are.\nYour turn: Change this code to add a specific bin width for city miles per gallon cty (hint: binwidth). Play around with different widths until you find one that represents the data well.\n  By default, histograms are filled with a dark grey color and the bars have no borders. Additionally, R places the center of the bars at specific numbers: if you have a bin width of 5, for instance, a bar will show the range from 7.5 to 12.5 instead of 5-10 or 10-15.\nYour turn: Do the following:\nAdd a specific bin width Add a white border (hint: color) Fill with #E16462 Make it so the bars start at whole numbers like 10 or 20 (hint: boundary)    You can add extra aesthetics to encode additional information about the distribution of variables across categories.\nYour turn: Make a histogram of cty and fill by drv (drive: front, rear, and 4-wheel). Make sure you specify a good bin width.\n  That’s too much information! Instead of only filling, you can separate the data into multiple plots.\nYour turn: Make a histogram of cty fill and facet by drv. Make sure you specify a good bin width. Make sure you specify a good bin width.\n   Density plots When working with density plots in this class you don’t need to worry too much about the calculus behind the scenes that creates the curves. But you can change those settings if you really want.\nYour turn: Do the following:\nFill this density plot with #E16462 Add a border (hint: color) using #9C3836, with size = 1 Change the bandwidth (hint: bw) to 0.5, then 1, then 10    Like histograms, you can map other variables onto the plot. It’s often a good idea to make the curves semi-transparent so you can see the different distributions.\nYour turn: Do the following:\nFill this plot using the drv variable Make the density plots 50% transparent    Even with transparency, it’s often difficult to interpret density plots like this. As an alternative, you can use the ggridges package to make ridge plots. Look at the documentation and examples for ggridges for lots of details about different plots you can make.\nYour turn: Convert this plot into a ridge plot.\n   Boxes, violins, and dots Finally, you can use things like boxplots and violin plots to show the distribution of variables, either by themselves or across categories.\nBox plots show the distribution of a variable by highlighting specific details, like the 25th, 50th (median) and 75th percentile, as well as the assumed minimum, assumed maximum, and outliers:\nAnatomy of a boxplot\n When making boxplots with ggplot, you need to map the variable of interest to the x aesthetic (or y if you want a vertical boxplot), and you can optionally map a second categorical variable to the y aesthetic (or x if you want a vertical boxplot).\nYou can adjust the fill and color of the plot, and you can change what counts as outliers with the coef argument. By default outliers are any point that is beyond the 75th percentile + 1.5 × the interquartile range (or below the 25th percentile + 1.5 × IQR), but that’s adjustable.\nYour turn: Do the following:\nFill the boxplot with #E6AD3C Color the boxplot with #5ABD51 Change the definition of outliers to be 5 times the IQR    You can also use violin plots instead of boxplot, which show the mirrored density distribution. When doing this, it’s often helpful to add other geoms like jittered points to show more of the data\nYour turn: Do the following\nChange this boxplot to use violins instead Add jittered points with a jittering width of 0.1 and sized at 0.5     ","date":1589760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"f4cd52ded401299a83d62039ff42e8b4","permalink":"https://uvaDS8104.github.io/lesson/06-lesson/","publishdate":"2020-05-18T00:00:00Z","relpermalink":"/lesson/06-lesson/","section":"lesson","summary":"Histograms Density plots Boxes, violins, and dots   Throughout this lesson, you’ll use the built-in mpg dataset to make histograms, density plots, box plots, violin plots, and other graphics that show uncertainty.\nSorry if mpg is getting repetitive! For short interactive things like this, it’s easier to use built-in and easy-to-load datasets like mpg and gapminder instead of loading CSV files, hence our constant reuse of the dataset.","tags":null,"title":"Uncertainty","type":"docs"},{"authors":null,"categories":null,"content":"  There isn’t really a lesson for today, and as we get further into the semester, the need for lessons will continue to decrease. Now that each section is focused on a few specific geoms and how to apply them, you don’t need to go through interactive tutorials so much, since you should (hopefully!) be getting the hang of how ggplot works. (IF NOT, please reach out for help on Slack or via e-mail! I’m more than happy and ready to help!)\nFor the lesson, read through the code examples in the example to see how to make dual y-axes, scatterplot matrices, coefficient plots, and marginal effects plots.\n","date":1589846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"36f453f698c7a3972914c894cffd917b","permalink":"https://uvaDS8104.github.io/lesson/07-lesson/","publishdate":"2020-05-19T00:00:00Z","relpermalink":"/lesson/07-lesson/","section":"lesson","summary":"There isn’t really a lesson for today, and as we get further into the semester, the need for lessons will continue to decrease. Now that each section is focused on a few specific geoms and how to apply them, you don’t need to go through interactive tutorials so much, since you should (hopefully!) be getting the hang of how ggplot works. (IF NOT, please reach out for help on Slack or via e-mail!","tags":null,"title":"Relationships","type":"docs"},{"authors":null,"categories":null,"content":"  Like yesterday, there isn’t really a lesson today. You’re not learning how to use any new functions—you’re learning how to apply the geoms you already know in cool and exciting ways. But don’t worry! You’ll have a lesson for session 9!\nFor the lesson, read through the code examples in the example to see how to make small multiples, sparklines, geofacets, and slopegraphs.\n","date":1589932800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"943054b07389b7a8559401831f3a8cd6","permalink":"https://uvaDS8104.github.io/lesson/08-lesson/","publishdate":"2020-05-20T00:00:00Z","relpermalink":"/lesson/08-lesson/","section":"lesson","summary":"Like yesterday, there isn’t really a lesson today. You’re not learning how to use any new functions—you’re learning how to apply the geoms you already know in cool and exciting ways. But don’t worry! You’ll have a lesson for session 9!\nFor the lesson, read through the code examples in the example to see how to make small multiples, sparklines, geofacets, and slopegraphs.","tags":null,"title":"Comparisons","type":"docs"},{"authors":null,"categories":null,"content":"  Ha, so in the video I said there would be interactive lessons, but I changed my mind! You’re only working with a few new functions this session (annotate(), geom_text(), geom_label(), geom_text_repel(), and geom_label_repel()), and the best way to figure out how to use them is to use them!\nThere are some helpful blog posts and other resources online with examples and explanations. Read through these in addition to the documentation for annotate(), geom_text()/geom_label() and ggrepelhttps://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html:\n  “Add shapes with annotate()”  “Annotations”  ","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"9ba3922ca694430b88b632d8dbab3bdb","permalink":"https://uvaDS8104.github.io/lesson/09-lesson/","publishdate":"2020-05-21T00:00:00Z","relpermalink":"/lesson/09-lesson/","section":"lesson","summary":"Ha, so in the video I said there would be interactive lessons, but I changed my mind! You’re only working with a few new functions this session (annotate(), geom_text(), geom_label(), geom_text_repel(), and geom_label_repel()), and the best way to figure out how to use them is to use them!\nThere are some helpful blog posts and other resources online with examples and explanations. Read through these in addition to the documentation for annotate(), geom_text()/geom_label() and ggrepelhttps://cran.","tags":null,"title":"Annotations","type":"docs"},{"authors":null,"categories":null,"content":"  Again, there’s no lesson for this. The only way to learn how to use ggplotly() and create dashboards with flexdashboard is to try them out in RStudio, not in a mini browser-based R session here.\nSo head over to the exercise to get started!\n","date":1590105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"86a399491d0977aee8295e2950c3a1b2","permalink":"https://uvaDS8104.github.io/lesson/10-lesson/","publishdate":"2020-05-22T00:00:00Z","relpermalink":"/lesson/10-lesson/","section":"lesson","summary":"Again, there’s no lesson for this. The only way to learn how to use ggplotly() and create dashboards with flexdashboard is to try them out in RStudio, not in a mini browser-based R session here.\nSo head over to the exercise to get started!","tags":null,"title":"Interactivity","type":"docs"},{"authors":null,"categories":null,"content":"  Once again, there’s no lesson this time. You’re all understanding the basics of R and ggplot and dplyr really well (I’m seriously so impressed and proud of you all!).\nIn your exercise today you’ll visualize trends in time using one of three different real-world datasets. In the example I demonstrate how to remove seasonality from time series data, which is a useful skill, but not always applicable to every time series dataset. If there’s no seasonality in your data, you don’t need to remove it.\nSo head over to the example or the exercise to get started!\n","date":1590451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"2cd5967b5ce567cec7f3684c70946623","permalink":"https://uvaDS8104.github.io/lesson/11-lesson/","publishdate":"2020-05-26T00:00:00Z","relpermalink":"/lesson/11-lesson/","section":"lesson","summary":"Once again, there’s no lesson this time. You’re all understanding the basics of R and ggplot and dplyr really well (I’m seriously so impressed and proud of you all!).\nIn your exercise today you’ll visualize trends in time using one of three different real-world datasets. In the example I demonstrate how to remove seasonality from time series data, which is a useful skill, but not always applicable to every time series dataset.","tags":null,"title":"Time","type":"docs"},{"authors":null,"categories":null,"content":"   Combining datasets vertically Combining datasets horizontally inner_join() left_join() Common column names right_join()   There is a short lesson today! You’ll learn the basics of joining two different datasets together, both vertically and horizontally.\nThere are a few imaginary datasets I’ve created for you to play with:\nx ## # A tibble: 3 x 2 ## id some_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y ## # A tibble: 3 x 2 ## id some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y4 national_data ## # A tibble: 9 x 5 ## state year unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 2018 5 2 100 ## 2 GA 2019 5.3 1.8 200 ## 3 GA 2020 5.2 2.5 300 ## 4 NC 2018 6.1 1.8 350 ## 5 NC 2019 5.9 1.6 375 ## 6 NC 2020 5.3 1.8 400 ## 7 CO 2018 4.7 2.7 200 ## 8 CO 2019 4.4 2.6 300 ## 9 CO 2020 5.1 2.5 400 national_data_2019 ## # A tibble: 3 x 4 ## state unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 5.3 1.8 200 ## 2 NC 5.9 1.6 375 ## 3 CO 4.4 2.6 300 national_libraries ## # A tibble: 6 x 4 ## state year libraries schools ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 CO 2018 230 470 ## 2 CO 2019 240 440 ## 3 CO 2020 270 510 ## 4 NC 2018 200 610 ## 5 NC 2019 210 590 ## 6 NC 2020 220 530 national_libraries_2019 ## # A tibble: 2 x 3 ## state libraries schools ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 CO 240 440 ## 2 NC 210 590 puerto_rico_data ## # A tibble: 3 x 4 ## state unemployment population year ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 PR 3.1 150 2018 ## 2 PR 3.2 250 2019 ## 3 PR 3.3 350 2020 state_regions ## # A tibble: 51 x 2 ## region state ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 West AK ## 2 South AL ## 3 South AR ## 4 West AZ ## 5 West CA ## 6 West CO ## 7 Northeast CT ## 8 South DC ## 9 South DE ## 10 South FL ## # … with 41 more rows Combining datasets vertically Recall from the Lord of the Rings data in exercise 3 that you had to combine three different CSV files into dataset. You used bind_rows() to stack each of these on top of each other.\nlotr \u0026lt;- bind_rows(fellowship, tt, rotk) That worked well because each of the individual data frames had the same columns in them, and R was able to line up the matching columns. If columns were missing, R would have placed NA in the appropriate locations.\nYour turn: Combine national_data and puerto_rico_data into a single dataset named us_data using bind_rows. Pay attention to what happens with the inflation column. Also notice that the columns in the Puerto Rico data are in a different order.\n   Combining datasets horizontally Binding rows vertically is the easiest way to combine two datasets, but most often you won’t be doing that. You’ll only do this if you’re combining datasets that come from the same source, like if a state offers separate CSV files of the same data for each county.\nIn most cases, though, you’ll need to combine completely different datasets, bringing one or more columns from one into another. With vertical combining, R needs column names with the same names in order to figure out where the data lines up. With horizontal combining, R needs values inside one or more columns to be the same in order to figure out where the data lines up.\nThere is technically a function named bind_cols(), but you’ll rarely want to use it. It doesn’t attempt to match any rows—it just glues two datasets together:\nbind_cols(national_data, # Repeat PR 3 times so that it has the same number of rows as national_data bind_rows(puerto_rico_data, puerto_rico_data, puerto_rico_data)) ## # A tibble: 9 x 9 ## state year unemployment inflation population state1 unemployment1 population1 ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 2018 5 2 100 PR 3.1 150 ## 2 GA 2019 5.3 1.8 200 PR 3.2 250 ## 3 GA 2020 5.2 2.5 300 PR 3.3 350 ## 4 NC 2018 6.1 1.8 350 PR 3.1 150 ## 5 NC 2019 5.9 1.6 375 PR 3.2 250 ## 6 NC 2020 5.3 1.8 400 PR 3.3 350 ## 7 CO 2018 4.7 2.7 200 PR 3.1 150 ## 8 CO 2019 4.4 2.6 300 PR 3.2 250 ## 9 CO 2020 5.1 2.5 400 PR 3.3 350 ## # … with 1 more variable: year1 \u0026lt;dbl\u0026gt; That’s… not great.\nInstead, we need to use a function that is more careful about bringing in data. Fortunately there are a few good options:\n inner_join() left_join() right_join()  The most helpful way of understanding these different functions is to go here and stare at the animations for a little while to see which pieces of which dataset go where. (There are lots of others, like full_join(), semi_join(), and anti_join(), and they have helpful animations, but I rarely use those.)\nFor each of these functions, you need at least one common ID column in both datasets in order for R to know where things line up.\nLet’s practice how these all work and see what the differences between them are.\n inner_join() First, go to this page in a new tab and stare at the mesmerizing animation.\nLet’s look at two datasets, x and y:\nx ## # A tibble: 3 x 2 ## id some_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y ## # A tibble: 3 x 2 ## id some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y4 Both datasets have an id column that is the same across each (though the values aren’t necessarily the same). Because there’s a shared column, we can join these two based on that column.\nIf we use inner_join(), the resulting dataset will only keep the rows from the first where there are matching values from the second:\ninner_join(x, y, by = \u0026quot;id\u0026quot;) ## # A tibble: 2 x 3 ## id some_variable some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 y1 ## 2 2 x2 y2 Notice how it got rid of the row with id = 3 from the first and the row with id = 4 from the second.\nYou can also write this with pipes, which is really common when working with dplyr:\nx %\u0026gt;% inner_join(y, by = \u0026quot;id\u0026quot;) ## # A tibble: 2 x 3 ## id some_variable some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 y1 ## 2 2 x2 y2 Let’s say we have two datasets: national_data_2019 and national_libraries_2019:\nnational_data_2019 ## # A tibble: 3 x 4 ## state unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 5.3 1.8 200 ## 2 NC 5.9 1.6 375 ## 3 CO 4.4 2.6 300 national_libraries_2019 ## # A tibble: 2 x 3 ## state libraries schools ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 CO 240 440 ## 2 NC 210 590 We want to bring the libraries and schools columns into the general national data. Notice how both datasets have a state column.\nYour turn: Create a new dataset named combined_data that uses inner_join() to merge national_data_2019 and national_libraries_2019.\n   left_join() Again, go to this page in a new tab and stare at the animation.\nLeft joining is less destructive than inner joining. With left joining, any rows in the first dataset that don’t have matches in the second don’t get thrown away and instead are filled with NA:\nleft_join(x, y, by = \u0026quot;id\u0026quot;) ## # A tibble: 3 x 3 ## id some_variable some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 \u0026lt;NA\u0026gt; Notice how the row with id = 4 from the second dataset is gone, but the row with id = 3 from the first is still there, with NA for some_other_variable.\nI find this much more useful when combining data. I often have a larger dataset with all the main variables I care about, perhaps with every combination of country and year over 20 years and 180 countries. If I find another dataset I want to join, and it has missing data for some of the years or countries, I don’t want the combined data to throw away all the rows from the main big dataset that don’t match! I still want those!\n(Look at this for a real life example: I create a dataset I name panel_skeleton that is just all the combinations of countries and years (Afghanistan 1990, Afghanistan 1991, etc.), and then I bring in all sorts of other datasets that match the same countries and years. When there aren’t matches, nothing in the skeleton gets thrown away—R just adds missing values instead.)\nYour turn: Create a new dataset named combined_data that uses left_join() to merge national_data_2019 and national_libraries_2019.\n  Left joining is also often surprisingly helpful for recoding lots of variables. Right now in our fake national data, we have a column for state, but it would be nice if we could have a column for region so we could facet or fill or color by region in a plot. Hunting around on the internet, you find this dataset that has a column for state and a column for abbreviations:\nstate_regions ## # A tibble: 51 x 2 ## region state ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 West AK ## 2 South AL ## 3 South AR ## 4 West AZ ## 5 West CA ## 6 West CO ## 7 Northeast CT ## 8 South DC ## 9 South DE ## 10 South FL ## # … with 41 more rows Your turn: Create a new dataset named national_data_with_region that uses left_join() to combine national_data_2019 with state_regions.\n  Because left_join() only keeps rows from the second dataset that match the first, we don’t actually bring in all 50 rows from the state_regions data—only the rows that match the first dataset (national_data_2019) come over. We could have done with if some massive recoding (mutate(region = ifelse(state == \"GA\" | state == \"NC\", \"South\", ifelse(state == \"CO\"), \"West\", NA))), but that’s awful. Left joining is far easier here.\nYou can also join by multiple columns. So far we’ve been working with just national_data_2019, but if you look at national_data, you’ll see there are rows for different years across these states:\nnational_data ## # A tibble: 9 x 5 ## state year unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 2018 5 2 100 ## 2 GA 2019 5.3 1.8 200 ## 3 GA 2020 5.2 2.5 300 ## 4 NC 2018 6.1 1.8 350 ## 5 NC 2019 5.9 1.6 375 ## 6 NC 2020 5.3 1.8 400 ## 7 CO 2018 4.7 2.7 200 ## 8 CO 2019 4.4 2.6 300 ## 9 CO 2020 5.1 2.5 400 Previously, we’ve been specifying the ID column with by = \"state\", but now we have two ID columns: state and year. We can specify both with by = c(\"state\", \"year\").\nYour turn: Create a new dataset named national_data_combined that uses left_join() to combine national_data with national_libraries by state and year.\n  If one dataset has things like state and year, but another only has state, left_join() will still work, but it will only join where the state is the same. For instance, here’s what happens when we join the region data to the yearly national data:\nnational_data_with_region \u0026lt;- national_data %\u0026gt;% left_join(state_regions, by = \u0026quot;state\u0026quot;) national_data_with_region ## # A tibble: 9 x 6 ## state year unemployment inflation population region ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 GA 2018 5 2 100 South ## 2 GA 2019 5.3 1.8 200 South ## 3 GA 2020 5.2 2.5 300 South ## 4 NC 2018 6.1 1.8 350 South ## 5 NC 2019 5.9 1.6 375 South ## 6 NC 2020 5.3 1.8 400 South ## 7 CO 2018 4.7 2.7 200 West ## 8 CO 2019 4.4 2.6 300 West ## 9 CO 2020 5.1 2.5 400 West The “South” region gets added to every row where the state is “GA” and “NC”, even though those rows only appear once in state_regions. left_join() will still match all the values even if states are repeated. Magic!\n Common column names So far, the column names in both datasets have been the same, which has greatly simplified life. In fact, if the columns have the same name, we can technically leave out the by argument and R will guess:\nnational_data %\u0026gt;% left_join(national_libraries) ## Joining, by = c(\u0026quot;state\u0026quot;, \u0026quot;year\u0026quot;) ## # A tibble: 9 x 7 ## state year unemployment inflation population libraries schools ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 2018 5 2 100 NA NA ## 2 GA 2019 5.3 1.8 200 NA NA ## 3 GA 2020 5.2 2.5 300 NA NA ## 4 NC 2018 6.1 1.8 350 200 610 ## 5 NC 2019 5.9 1.6 375 210 590 ## 6 NC 2020 5.3 1.8 400 220 530 ## 7 CO 2018 4.7 2.7 200 230 470 ## 8 CO 2019 4.4 2.6 300 240 440 ## 9 CO 2020 5.1 2.5 400 270 510 It’s good practice to be specific about the columns you want and actually use by, but I will often run left_join() without it and then copy the message that it generates (“by = c(\"state\", \"year\")”) and paste it into my code.\nBut what if the column names don’t match? Let’s rename the state column in our state/region table for fun:\nstate_regions_different \u0026lt;- state_regions %\u0026gt;% rename(ST = state) state_regions_different ## # A tibble: 51 x 2 ## region ST ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 West AK ## 2 South AL ## 3 South AR ## 4 West AZ ## 5 West CA ## 6 West CO ## 7 Northeast CT ## 8 South DC ## 9 South DE ## 10 South FL ## # … with 41 more rows Now watch what happens when we try to join the datasets:\nnational_data %\u0026gt;% left_join(state_regions_different) ## Error: `by` required, because the data sources have no common variables There are no common variables, so we get an error. The state and ST columns really are common variables, but R doesn’t know that.\nWe have two options:\nRename one of the columns so it matches (either change state to ST or change ST to state) Tell left_join() which columns are the same  We can do option two by modifying the by argument like so:\nnational_data %\u0026gt;% left_join(state_regions_different, by = c(\u0026quot;state\u0026quot; = \u0026quot;ST\u0026quot;)) ## # A tibble: 9 x 6 ## state year unemployment inflation population region ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 GA 2018 5 2 100 South ## 2 GA 2019 5.3 1.8 200 South ## 3 GA 2020 5.2 2.5 300 South ## 4 NC 2018 6.1 1.8 350 South ## 5 NC 2019 5.9 1.6 375 South ## 6 NC 2020 5.3 1.8 400 South ## 7 CO 2018 4.7 2.7 200 West ## 8 CO 2019 4.4 2.6 300 West ## 9 CO 2020 5.1 2.5 400 West  right_join() Once again, go to this page in a new tab and watch the animation.\nright_join() works exactly like left_join(), but in reverse. The second dataset is the base data. Any rows in the second dataset that don’t match in the first will be kept, and any rows from the first that don’t match will get thrown away.\nWatch what happens if we right join national_data and state_regions:\nnational_data %\u0026gt;% right_join(state_regions, by = \u0026quot;state\u0026quot;) ## # A tibble: 57 x 6 ## state year unemployment inflation population region ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 AK NA NA NA NA West ## 2 AL NA NA NA NA South ## 3 AR NA NA NA NA South ## 4 AZ NA NA NA NA West ## 5 CA NA NA NA NA West ## 6 CO 2018 4.7 2.7 200 West ## 7 CO 2019 4.4 2.6 300 West ## 8 CO 2020 5.1 2.5 400 West ## 9 CT NA NA NA NA Northeast ## 10 DC NA NA NA NA South ## # … with 47 more rows Yikes. R kept all the rows in state_regions, brought in the columns from national_data and filled most of the new columns with NA, and then repeated Colorado (and NC and GA) three times for each of the years from national_data. That’s a mess.\nIf we reverse the order, we’ll get the correct merged data:\nstate_regions %\u0026gt;% right_join(national_data, by = \u0026quot;state\u0026quot;) ## # A tibble: 9 x 6 ## region state year unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 South GA 2018 5 2 100 ## 2 South GA 2019 5.3 1.8 200 ## 3 South GA 2020 5.2 2.5 300 ## 4 South NC 2018 6.1 1.8 350 ## 5 South NC 2019 5.9 1.6 375 ## 6 South NC 2020 5.3 1.8 400 ## 7 West CO 2018 4.7 2.7 200 ## 8 West CO 2019 4.4 2.6 300 ## 9 West CO 2020 5.1 2.5 400 I rarely use right_join() because I find it more intuitive to just use left_join() since in my head, I’m taking a dataset and stacking columns onto the end of it. If you want to right join instead, neat—just remember to order things correctly.\n ","date":1590537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"05e82a05a3ed4f364a54f9dff01f853b","permalink":"https://uvaDS8104.github.io/lesson/12-lesson/","publishdate":"2020-05-27T00:00:00Z","relpermalink":"/lesson/12-lesson/","section":"lesson","summary":"Combining datasets vertically Combining datasets horizontally inner_join() left_join() Common column names right_join()   There is a short lesson today! You’ll learn the basics of joining two different datasets together, both vertically and horizontally.\nThere are a few imaginary datasets I’ve created for you to play with:\nx ## # A tibble: 3 x 2 ## id some_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y ## # A tibble: 3 x 2 ## id some_other_variable ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y4 national_data ## # A tibble: 9 x 5 ## state year unemployment inflation population ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GA 2018 5 2 100 ## 2 GA 2019 5.","tags":null,"title":"Space","type":"docs"},{"authors":null,"categories":null,"content":"  There’s no lesson for this session. In your exercise today you’ll visualize text data using tidytext, and the best way to figure that out is to just play with data.\nSo head over to the example to see how it’s done, or the exercise to get started!\n","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"2ea81152b1f77e665a1de070264de2ad","permalink":"https://uvaDS8104.github.io/lesson/13-lesson/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/lesson/13-lesson/","section":"lesson","summary":"There’s no lesson for this session. In your exercise today you’ll visualize text data using tidytext, and the best way to figure that out is to just play with data.\nSo head over to the example to see how it’s done, or the exercise to get started!","tags":null,"title":"Text","type":"docs"},{"authors":null,"categories":null,"content":"  There’s no lesson for this session. In your exercise today you’ll export a plot from ggplot, open it in a vector editor like Illustrator, Inkscape, or Gravit Designer, and make it extra pretty and well-designed. The best way to learn this is by actually doing it.\nSo head over to the example to see how it’s done, or the exercise to get started!\n","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"ee37ad1d5277682b8171e2f97b60b0a5","permalink":"https://uvaDS8104.github.io/lesson/14-lesson/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/lesson/14-lesson/","section":"lesson","summary":"There’s no lesson for this session. In your exercise today you’ll export a plot from ggplot, open it in a vector editor like Illustrator, Inkscape, or Gravit Designer, and make it extra pretty and well-designed. The best way to learn this is by actually doing it.\nSo head over to the example to see how it’s done, or the exercise to get started!","tags":null,"title":"Enhancing graphics","type":"docs"},{"authors":null,"categories":null,"content":"  There’s no lesson for this session. You made it to the end of the course! Congratulations!\n","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"eba25e9e890c63b7e08cf49cf2816105","permalink":"https://uvaDS8104.github.io/lesson/15-lesson/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/lesson/15-lesson/","section":"lesson","summary":"There’s no lesson for this session. You made it to the end of the course! Congratulations!","tags":null,"title":"Truth, beauty, and data revisited","type":"docs"},{"authors":null,"categories":null,"content":"Readings    Chapters 1 \u0026amp; 2 in Easley \u0026amp; Kleinberg, Networks, crowds, and markets: Reasoning about a highly connected world The full book is here, too.\n   Butts, Carter T. (2009) \u0026ldquo;Revisiting the foundations of network analysis.\u0026rdquo; Science 325, no. 5939: 414-416.\n  Slides The slides for today\u0026rsquo;s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n","date":1674000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674000000,"objectID":"9f210e786ac3c6ae3a61cb9aaebcdc5c","permalink":"https://uvaDS8104.github.io/content/01-content/","publishdate":"2023-01-18T00:00:00Z","relpermalink":"/content/01-content/","section":"content","summary":"Readings    Chapters 1 \u0026amp; 2 in Easley \u0026amp; Kleinberg, Networks, crowds, and markets: Reasoning about a highly connected world The full book is here, too.\n   Butts, Carter T. (2009) \u0026ldquo;Revisiting the foundations of network analysis.\u0026rdquo; Science 325, no. 5939: 414-416.\n  Slides The slides for today\u0026rsquo;s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later).","tags":null,"title":"Why study networks?","type":"docs"},{"authors":null,"categories":null,"content":"  Here’s your roadmap for the mini-mester!\nEvery class session has four important sections. You should read about the details for each using the main menu at the top of this webpage.\n Content (): This page contains the readings, slides, and recorded lectures for the topic. Read and watch these first each day. Lesson (): This page contains an interactive lesson that teaches you the principles and code you need to know. Go through these after doing the content. Example (): This page contains fully annotated R code that you can use as a reference for creating your own visualizations. This is only a reference page—you don’t have to necessarily do anything here. Each section also contains videos of me live coding the examples so you can see what it looks like to work with R in real time. This page will be very helpful as you work on your assignments. Assignment (): This page contains the instructions for either the session exercise (1–3 brief tasks), or for the two mini projects and final project. Assignments are due by 11:59 PM on the day they’re listed.  tl;dr: You should follow this general process each day:\n Do everything on the content () page Work through the lesson () page Complete the assignment () while referencing the example ()      Foundations Content Lesson Example Assignment   May 11 Truth, beauty, and data + R and tidyverse       May 12 Graphic design       May 13 Mapping data to graphics        Core types of graphics Content Lesson Example Assignment   May 14 Amounts and proportions       May 15 Themes       May 18 Uncertainty       May 19 Relationships       May 20 Comparisons       May 21 Annotations       May 22  Mini project 1 due           Special applications Content Lesson Example Assignment   May 22 Interactivity       May 26 Time       May 27 Space       May 28 Text       May 29 Enhancing graphics       May 29  Mini project 2 due           Conclusions Content Lesson Example Assignment   June 1 Truth, beauty, and data revisited       June 5  Final project due           ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"https://uvaDS8104.github.io/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Here’s your roadmap for the mini-mester!\nEvery class session has four important sections. You should read about the details for each using the main menu at the top of this webpage.\n Content (): This page contains the readings, slides, and recorded lectures for the topic. Read and watch these first each day. Lesson (): This page contains an interactive lesson that teaches you the principles and code you need to know.","tags":null,"title":"Schedule","type":"page"},{"authors":null,"categories":null,"content":"   Course objectives Important pep talk! Course materials  Books, articles, and other materials R and RStudio Online help  Course policies  Student hours Class conduct and expectations Learning during a pandemic Counseling and Psychological Services (CPS) Basic needs security Lauren’s Promise Academic honesty Special needs  Assignments and grades Star Wars   Instructor  Dr. Alexander Gates  164A Elson Hall  agates@virginia.edu  @complexgates  Schedule an appointment   Course details  Tu, Th  January 19 - April 27, 2023  2:00pm - 3:15pm  Elliwood Conference Room   Contacting me E-mail is the best way to get in contact with me. I will try to respond to all course-related e-mails within 24 hours (yup), but also remember that life can be busy and chaotic for everyone (including me!), so if I don\u0026rsquo;t respond right away, don\u0026rsquo;t worry!\n  Course objectives Data rarely speaks for itself. On their own, the facts contained in raw data are difficult to understand, and in the absence of beauty and order, it is impossible to understand the truth that the data shows.\nIn this class, you’ll learn how to use industry-standard graphic and data design techniques to create beautiful, understandable visualizations and uncover truth in data.\nBy the end of this course, you will become (1) literate in data and graphic design principles, and (2) an ethical data communicator, by producing beautiful, powerful, and clear visualizations of your own data. Specifically, you should:\n Understand the principles of data and graphic design Evaluate the credibility, ethics, and aesthetics of data visualizations Create well-designed data visualizations with appropriate tools Share data and graphics in open forums Be curious and confident in consuming and producing data visualizations  This class will expose you to R—one of the most popular, sought-after, and in-demand statistical programming languages. Armed with the foundation of R skills you’ll learn in this class, you’ll know enough to be able to find how to visualize and analyze any sort of data-based question in the future.\n Important pep talk! I promise you can succeed in this class.\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2—made this wise observation:\n It’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n Even experienced programmers find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail me, etc.\n\n Course materials All of the readings and software in this class are free. There are free online version of all the textbooks, R and RStudio are inherently free, and GSU provides free access to Adobe Illustrator.\nBooks, articles, and other materials We’ll rely heavily on these books, which are all available online (for free!). I recommend getting the printed versions of these books if you are interested, but it is not required.\n Alberto Cairo, The Truthful Art: Data, Charts, and Maps for Communication (Berkeley, California: New Riders, 2016).\n $27 used, $32 new at Amazon. A free eBook version is available through GSU’s library through O’Reilly’s Higher Education database. The easiest way to access it is to visit a special URL (http://go.oreilly.com/georgia-state-university), log in with your GSU account, and then search for “The Truthful Art”.\n Kieran Healy, Data Visualization: A Practical Introduction (Princeton: Princeton University Press, 2018), http://socviz.co/.\n FREE online; $30 used, $36 new at Amazon.\n Claus E. Wilke, Fundamentals of Data Visualization (Sebastopol, California: O’Reilly Media, 2018), https://serialmentor.com/dataviz/.\n FREE online; $32 new at Amazon. An eBook version is also available through the O’Reilly database, but you can just use the online version.\n  There will occasionally be additional articles and videos to read and watch. When this happens, links to these other resources will be included on the content page for that session.\nI also highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\n R and RStudio You will do all of your analysis with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations produces the actual statistics and graphical output, while RStudio provides a nice interface for running R code.\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for examples, exercises, and mini projects.\nRStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets or more complicated analysis and graphics. You also can’t use your own custom fonts with RStudio.cloud. Over the course of the semester, you’ll probably want to get around to installing R, RStudio, and other R packages on your computer and wean yourself off of RStudio.cloud. This isn’t 100% necessary, but it’s helpful.\nYou can find instructions for installing R, RStudio, and all the tidyverse packages here.\n Online help Data science and statistical programming can be difficult. Computers are stupid and little errors in your code can cause hours of headache (even if you’ve been doing this stuff for years!).\nFortunately there are tons of online resources to help you with this. Two of the most important are StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful.\nSearching for help with R on Google can sometimes be tricky because the program name is, um, a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work will deal with ggplot2, it’s often easier to just search for that instead of the letter “r” (e.g. “ggplot scatterplot”).\nAdditionally, we have a class chatroom at Slack where anyone in the class can ask questions and anyone can answer. I will monitor Slack regularly and will respond quickly. (It’s one of the rare Slack workspaces where I actually have notifications enabled!) Ask questions about the readings, exercises, and mini projects. You’ll likely have similar questions as your peers, and you’ll likely be able to answer other peoples’ questions too.\n  Course policies Be nice. Be honest. Don’t cheat.\nWe will also follow Georgia State’s Code of Conduct.\nThis syllabus reflects a plan for the mini-mester. Deviations may become necessary as the course progresses.\nStudent hours Please watch this video:\n Student hours are set times dedicated to all of you (most professors call these “office hours”; I don’t1). This means that I will be in my office at home (wistfully) waiting for you to come by talk to me remotely with whatever questions you have. This is the best and easiest way to find me and the best chance for discussing class material and concerns.\nBecause of the pandemic, we cannot meet in person. I can meet you online via Webex. Use this link for regular student hours: https://gsumeetings.webex.com/meet/aheiss. You can also easily [make an appointment You can also find me through e-mail and Slack.\n Class conduct and expectations Here are the rules, expectations, and policies that we came up with collectively:\n Late work: You will lose 1 point per day for each day an assigment or problem set is late. After 1 week, I will send a reminder e-mail. After 2 weeks, you will receive no points. Technology use: Use phones, computers, etc. responsibly. You’re all adults. Participation: Ensure that you are engaged and participate in class. Engagement is defined by you—if that means commenting and answering questions, neat; if it means sitting quietly and being focused, also neat.   Learning during a pandemic Life absolutely sucks right now.\nYou most likely know people who have lost their jobs, have tested positive for COVID-19, have been hospitalized, or perhaps have even died. You all have increased (or possibly decreased) work responsibilities and increased family care responsibilities—you might be caring for extra people (young and/or old!) right now, and you are likely facing uncertain job prospects (or have been laid off!).\nI’m fully committed to making sure that you learn everything you were hoping to learn from this class! I will make whatever accommodations I can to help you finish your exercises, do well on your projects, and learn and understand the class material. Under ordinary conditions, I am flexible and lenient with grading and course expectations when students face difficult challenges. Under pandemic conditions, that flexibility and leniency is intensified.\nIf you feel like you’re behind or not understanding everything, do not suffer in silence! Talk to me! Please sign up for a time to meet with me during student hours at https://calendly.com/andrewheiss/meeting/. I’m also available through e-mail and Slack. Remember, this is the only Slack account where I’ve enabled notifications!\nI want you to learn lots of things from this class (Graphic design! Fancy charts! R! ggplot!), but I primarily want you to stay healthy, balanced, and grounded during this crisis.\n Counseling and Psychological Services (CPS) Life at GSU can be complicated and challenging (especially during a pandemic!). You might feel overwhelmed, experience anxiety or depression, or struggle with relationships or family responsibilities. Counseling and Psychological Services (CPS) provides free, confidential support for students who are struggling with mental health and emotional challenges. The CPS office is staffed by professional psychologists who are attuned to the needs of all types of college and professional students. Please do not hesitate to contact CPS for assistance—getting help is a smart and courageous thing to do.\n Basic needs security If you have difficulty affording groceries or accessing sufficient food to eat every day, or if you lack a safe and stable place to live, and you believe this may affect your performance in this course, please contact the Dean of Students for support. They can provide a host of services including free groceries from the Panther Pantry and assisting with homelessness with the Embark Network. Additionally, please talk to me if you are comfortable in doing so. This will enable me to provide any resources that I might possess.\n Lauren’s Promise I will listen and believe you if someone is threatening you.\nLauren McCluskey, a 21-year-old honors student athlete, was murdered on October 22, 2018 by a man she briefly dated on the University of Utah campus. We must all take action to ensure that this never happens again.\nIf you are in immediate danger, call 911 or GSU police (404-413-3333).\nIf you are experiencing sexual assault, domestic violence, or stalking, please report it to me and I will connect you to resources or call GSU’s Counseling and Psychological Services (404-413-1640).\nAny form of sexual harassment or violence will not be excused or tolerated at Georgia State. GSU has instituted procedures to respond to violations of these laws and standards, programs aimed at the prevention of such conduct, and intervention on behalf of the victims. Georgia State University Police officers will treat victims of sexual assault, domestic violence, and stalking with respect and dignity. Advocates on campus and in the community can help with victims’ physical and emotional health, reporting options, and academic concerns.\n Academic honesty Violation of GSU’s Policy on Academic Honesty will result in an F in the course and possible disciplinary action.2 All violations will be formally reported to the Dean of Students.\n Special needs Students who wish to request accommodation for a disability may do so by registering with the Office of Disability Services. Students may only be accommodated upon issuance by the Office of Disability Services of a signed Accommodation Plan and are responsible for providing a copy of that plan to instructors of all classes in which accommodations are sought.\nStudents with special needs should then make an appointment with me during the first week of class to discuss any accommodations that need to be made.\n  Assignments and grades You can find descriptions for all the assignments on the assignments page.\n   Assignment Points Percent    Reflections (15 × 10) 150 23%  Exercises (15 × 10) 150 23%  Mini project 1 75 12%  Mini project 2 75 12%  Final project 200 31%  Total 650 —        Grade Range Grade Range    A 93–100% C 73–76%  A− 90–92% C− 70–72%  B+ 87–89% D+ 67–69%  B 83–86% D 63–66%  B− 80–82% D− 60–62%  C+ 77–79% F \u0026lt; 60%      Star Wars Once you have read this entire syllabus and the assignments page, please click here and e-mail me a picture of a cute Star Wars character.3 Brownie points if it’s animated.\n   There’s fairly widespread misunderstanding about what office hours actually are! Many students often think that they are the times I shouldn’t be disturbed, which is the exact opposite of what they’re for!↩︎\n So seriously, just don’t cheat or plagiarize!↩︎\n Baby Yoda, Babu Frik, porgs, etc. are all super fair game.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673993163,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"https://uvaDS8104.github.io/syllabus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Course objectives Important pep talk! Course materials  Books, articles, and other materials R and RStudio Online help  Course policies  Student hours Class conduct and expectations Learning during a pandemic Counseling and Psychological Services (CPS) Basic needs security Lauren’s Promise Academic honesty Special needs  Assignments and grades Star Wars   Instructor  Dr. Alexander Gates  164A Elson Hall  agates@virginia.edu  @complexgates  Schedule an appointment   Course details  Tu, Th  January 19 - April 27, 2023  2:00pm - 3:15pm  Elliwood Conference Room   Contacting me E-mail is the best way to get in contact with me.","tags":null,"title":"Syllabus","type":"page"}]